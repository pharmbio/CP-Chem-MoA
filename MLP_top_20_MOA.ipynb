{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75-UZEGR1A0b"
      },
      "outputs": [],
      "source": [
        "# install rdkit  \n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c rdkit rdkit python=3.7\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import pprint     \n",
        "pprint.pprint(sys.path)\n",
        "!python -c \"import site; print (site.getsitepackages())\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('top_20_MOAs.txt', sep = '\\t')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O9GYJo2v9Zu9",
        "outputId": "883e411a-bbe1-4609-c661-2c89955a73fc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                SMILES  \\\n",
              "0             CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O   \n",
              "1          COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1   \n",
              "2                            CC(C)NCC(O)COc1ccccc1CC=C   \n",
              "3     COc1ccccc1N1CCN(CCN2C(=O)c3ccccc3C(C)(C)C2=O)CC1   \n",
              "4            CC(C)(C)NCC(O)CSc1nc(cs1)-c1ccc(s1)C(N)=O   \n",
              "...                                                ...   \n",
              "1216                                        OCCCC(O)=O   \n",
              "1217              CN1c2ccc(Cl)cc2C(=NC(O)C1=O)c1ccccc1   \n",
              "1218          CCN(C(C)=O)c1cccc(c1)-c1ccnc2c(cnn12)C#N   \n",
              "1219     CCOC(=O)c1ncc2[nH]c3ccc(OCc4ccccc4)cc3c2c1COC   \n",
              "1220         CN(C)C(=O)Cc1c(nc2ccc(C)cn12)-c1ccc(C)cc1   \n",
              "\n",
              "                                  MOA  \n",
              "0      adrenergic receptor antagonist  \n",
              "1      adrenergic receptor antagonist  \n",
              "2      adrenergic receptor antagonist  \n",
              "3      adrenergic receptor antagonist  \n",
              "4      adrenergic receptor antagonist  \n",
              "...                               ...  \n",
              "1216  benzodiazepine receptor agonist  \n",
              "1217  benzodiazepine receptor agonist  \n",
              "1218  benzodiazepine receptor agonist  \n",
              "1219  benzodiazepine receptor agonist  \n",
              "1220  benzodiazepine receptor agonist  \n",
              "\n",
              "[1221 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9b55541e-8b8f-4c42-8605-3da324f79326\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(C)NCC(O)COc1ccccc1CC=C</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COc1ccccc1N1CCN(CCN2C(=O)c3ccccc3C(C)(C)C2=O)CC1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(C)(C)NCC(O)CSc1nc(cs1)-c1ccc(s1)C(N)=O</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1216</th>\n",
              "      <td>OCCCC(O)=O</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1217</th>\n",
              "      <td>CN1c2ccc(Cl)cc2C(=NC(O)C1=O)c1ccccc1</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218</th>\n",
              "      <td>CCN(C(C)=O)c1cccc(c1)-c1ccnc2c(cnn12)C#N</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219</th>\n",
              "      <td>CCOC(=O)c1ncc2[nH]c3ccc(OCc4ccccc4)cc3c2c1COC</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>CN(C)C(=O)Cc1c(nc2ccc(C)cn12)-c1ccc(C)cc1</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1221 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9b55541e-8b8f-4c42-8605-3da324f79326')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9b55541e-8b8f-4c42-8605-3da324f79326 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9b55541e-8b8f-4c42-8605-3da324f79326');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the duplicates \n",
        "for i in df.SMILES.tolist():\n",
        "  if df.SMILES.tolist().count(i) != 1:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "6S0Cz1ly_sZk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOA_class_dictionary = {'EGFR inhibitor': 8,\n",
        " 'HDAC inhibitor': 16,\n",
        " 'PI3K inhibitor': 13,\n",
        " 'acetylcholine receptor agonist': 1,\n",
        " 'acetylcholine receptor antagonist': 4,\n",
        " 'adrenergic receptor agonist': 18,\n",
        " 'adrenergic receptor antagonist': 15,\n",
        " 'bacterial cell wall synthesis inhibitor': 14,\n",
        " 'benzodiazepine receptor agonist': 10,\n",
        " 'calcium channel blocker': 5,\n",
        " 'cyclooxygenase inhibitor': 6,\n",
        " 'dopamine receptor antagonist': 12,\n",
        " 'glucocorticoid receptor agonist': 9,\n",
        " 'glutamate receptor antagonist': 19,\n",
        " 'histamine receptor antagonist': 17,\n",
        " 'phosphodiesterase inhibitor': 3,\n",
        " 'serotonin receptor agonist': 7,\n",
        " 'serotonin receptor antagonist': 2,\n",
        " 'sodium channel blocker': 11,\n",
        " 'topoisomerase inhibitor': 0}"
      ],
      "metadata": {
        "id": "17c5-JuGBwb0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_classes = list(MOA_class_dictionary.values())\n",
        "sorted_classes.sort() \n",
        "assert sorted_classes == [i for i in range(20)]"
      ],
      "metadata": {
        "id": "NkFqARR_B72C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add classes column \n",
        "df['classes'] = None\n",
        "for i in range(df.shape[0]):\n",
        "  df.iloc[i,2] = MOA_class_dictionary[df.iloc[i,1]]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lF5D5wb6CRCn",
        "outputId": "fe98861d-889e-4192-bb70-3e562ee22f10"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                SMILES  \\\n",
              "0             CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O   \n",
              "1          COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1   \n",
              "2                            CC(C)NCC(O)COc1ccccc1CC=C   \n",
              "3     COc1ccccc1N1CCN(CCN2C(=O)c3ccccc3C(C)(C)C2=O)CC1   \n",
              "4            CC(C)(C)NCC(O)CSc1nc(cs1)-c1ccc(s1)C(N)=O   \n",
              "...                                                ...   \n",
              "1216                                        OCCCC(O)=O   \n",
              "1217              CN1c2ccc(Cl)cc2C(=NC(O)C1=O)c1ccccc1   \n",
              "1218          CCN(C(C)=O)c1cccc(c1)-c1ccnc2c(cnn12)C#N   \n",
              "1219     CCOC(=O)c1ncc2[nH]c3ccc(OCc4ccccc4)cc3c2c1COC   \n",
              "1220         CN(C)C(=O)Cc1c(nc2ccc(C)cn12)-c1ccc(C)cc1   \n",
              "\n",
              "                                  MOA classes  \n",
              "0      adrenergic receptor antagonist      15  \n",
              "1      adrenergic receptor antagonist      15  \n",
              "2      adrenergic receptor antagonist      15  \n",
              "3      adrenergic receptor antagonist      15  \n",
              "4      adrenergic receptor antagonist      15  \n",
              "...                               ...     ...  \n",
              "1216  benzodiazepine receptor agonist      10  \n",
              "1217  benzodiazepine receptor agonist      10  \n",
              "1218  benzodiazepine receptor agonist      10  \n",
              "1219  benzodiazepine receptor agonist      10  \n",
              "1220  benzodiazepine receptor agonist      10  \n",
              "\n",
              "[1221 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7488b8ae-1060-4d7c-ae95-41f15ddf80ef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(C)NCC(O)COc1ccccc1CC=C</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>COc1ccccc1N1CCN(CCN2C(=O)c3ccccc3C(C)(C)C2=O)CC1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CC(C)(C)NCC(O)CSc1nc(cs1)-c1ccc(s1)C(N)=O</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1216</th>\n",
              "      <td>OCCCC(O)=O</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1217</th>\n",
              "      <td>CN1c2ccc(Cl)cc2C(=NC(O)C1=O)c1ccccc1</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1218</th>\n",
              "      <td>CCN(C(C)=O)c1cccc(c1)-c1ccnc2c(cnn12)C#N</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219</th>\n",
              "      <td>CCOC(=O)c1ncc2[nH]c3ccc(OCc4ccccc4)cc3c2c1COC</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1220</th>\n",
              "      <td>CN(C)C(=O)Cc1c(nc2ccc(C)cn12)-c1ccc(C)cc1</td>\n",
              "      <td>benzodiazepine receptor agonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1221 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7488b8ae-1060-4d7c-ae95-41f15ddf80ef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7488b8ae-1060-4d7c-ae95-41f15ddf80ef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7488b8ae-1060-4d7c-ae95-41f15ddf80ef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that changes smiles string to fingerprints \n",
        "import rdkit\n",
        "import numpy as np\n",
        "from rdkit import *\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "def smiles_to_array_to_string(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays  = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = list((np.squeeze(x_array)).astype(int))\n",
        "  string = ''\n",
        "  for i in x_array:\n",
        "    string += str(i) \n",
        "  return string"
      ],
      "metadata": {
        "id": "RfbsXXcT_sb7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the existence of Isomers\n",
        "assert len(set([smiles_to_array_to_string(i) for i in df.SMILES.tolist()])) == df.shape[0]"
      ],
      "metadata": {
        "id": "1u3oVoqMFh94"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CFagctK7GiTn",
        "outputId": "a84c14ad-431e-4c18-f682-11871e701b1e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        SMILES  \\\n",
              "0     CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O   \n",
              "1  COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1   \n",
              "2                    CC(C)NCC(O)COc1ccccc1CC=C   \n",
              "\n",
              "                              MOA classes  \n",
              "0  adrenergic receptor antagonist      15  \n",
              "1  adrenergic receptor antagonist      15  \n",
              "2  adrenergic receptor antagonist      15  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b96f7cce-525f-4c6a-ae64-74c0c6a1c727\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>CCCC(=O)Nc1ccc(OCC(O)CNC(C)C)c(c1)C(C)=O</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>COc1cc2nc(nc(N)c2cc1OC)N(C)CCCNC(=O)C1CCCO1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CC(C)NCC(O)COc1ccccc1CC=C</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b96f7cce-525f-4c6a-ae64-74c0c6a1c727')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b96f7cce-525f-4c6a-ae64-74c0c6a1c727 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b96f7cce-525f-4c6a-ae64-74c0c6a1c727');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xowg0CstLlC-"
      },
      "outputs": [],
      "source": [
        "# Split out the test set  \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_valid, x_test, y_train_valid, y_test = train_test_split(df.SMILES, df.classes, test_size =10/100,\n",
        " stratify = df.classes, shuffle = True, random_state = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BLlcRhSeU6xW"
      },
      "outputs": [],
      "source": [
        "# kfold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits = 9)\n",
        "skf.get_n_splits(np.array(list(x_train_valid)), np.array(list(y_train_valid)))\n",
        "train_index_list = []\n",
        "valid_index_list = []\n",
        "for train_index, valid_index in skf.split(np.array(list(x_train_valid)), np.array(list(y_train_valid))):\n",
        "  train_index_list.append(train_index)\n",
        "  valid_index_list.append(valid_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_list = []\n",
        "for i in range(9):\n",
        "  a_list += list(np.array(list(x_train_valid))[valid_index_list[i]])"
      ],
      "metadata": {
        "id": "JQT77vDlTeNy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DEqt9fUnDqBe"
      },
      "outputs": [],
      "source": [
        "number_of_kfold = 0 # change the number from 0-8 to get 9 shuffles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aOFIJo5MEMT0"
      },
      "outputs": [],
      "source": [
        "  x_train = list(np.array(list(x_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  x_valid = list(np.array(list(x_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  y_train = list(np.array(list(y_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  y_valid = list(np.array(list(y_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  x_test = list(x_test)\n",
        "  y_test = list(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L0OPr-gtR8sj"
      },
      "outputs": [],
      "source": [
        "# turn to cannoical  smiles\n",
        "x_train = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_train]\n",
        "x_valid = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_valid]\n",
        "x_test = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZB4WWi8wKB59"
      },
      "outputs": [],
      "source": [
        "def smiles_to_array(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = ((np.squeeze(x_array)).astype(int)) \n",
        "  return x_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a6Fy6iGdLSVP"
      },
      "outputs": [],
      "source": [
        "train_x = np.zeros((len(x_train), 2048), dtype = np.float32)\n",
        "for f in range(train_x.shape[0]):\n",
        "  train_x[f] = smiles_to_array(x_train[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dKhQc7EOKHMM"
      },
      "outputs": [],
      "source": [
        "valid_x = np.zeros((len(x_valid), 2048), dtype = np.float32)\n",
        "for f in range(valid_x.shape[0]):\n",
        "  valid_x[f] = smiles_to_array(x_valid[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eSJBpQREMRYr"
      },
      "outputs": [],
      "source": [
        "test_x = np.zeros((len(x_test), 2048), dtype = np.float32)\n",
        "for f in range(test_x.shape[0]):\n",
        "  test_x[f] = smiles_to_array(x_test[f])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are overlaps\n",
        "overlap = []\n",
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "7rWxLD37banf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(test_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(test_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "gxflY746cryJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(test_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], test_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "hbAAMsqPcr0y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(overlap) == 0"
      ],
      "metadata": {
        "id": "YNCJ9YgpoLTV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "557ApFkFa6j7"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).astype(int)\n",
        "y_valid = np.array(y_valid).astype(int)\n",
        "y_test = np.array(y_test).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eL24GiF7rCVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5685bc0c-9128-45b2-e26f-b70a632656b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import gc               \n",
        "gc.collect() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KlcQEfe9M-VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09723f29-c0df-4dd1-e1f3-1844680d9942"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.6266666666666667,\n",
              " 1: 1.4352941176470588,\n",
              " 2: 0.8872727272727273,\n",
              " 3: 0.976,\n",
              " 4: 0.7283582089552239,\n",
              " 5: 1.3555555555555556,\n",
              " 6: 0.6177215189873417,\n",
              " 7: 0.9959183673469387,\n",
              " 8: 1.525,\n",
              " 9: 1.318918918918919,\n",
              " 10: 1.7428571428571429,\n",
              " 11: 1.5741935483870968,\n",
              " 12: 0.976,\n",
              " 13: 1.4352941176470588,\n",
              " 14: 0.6506666666666666,\n",
              " 15: 0.6506666666666666,\n",
              " 16: 1.5741935483870968,\n",
              " 17: 0.8714285714285714,\n",
              " 18: 0.7283582089552239,\n",
              " 19: 0.8133333333333334}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Create class weights\n",
        "from sklearn.utils import class_weight\n",
        "y_unique = np.unique(np.array(y_train))\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = y_unique,\n",
        "                y = np.array(y_train)) \n",
        "class_weights_dict45 = dict(enumerate(class_weights))\n",
        "class_weights_dict45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ta8ysiFqNkpJ"
      },
      "outputs": [],
      "source": [
        "# The architecture of model      \n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "num = len(set(df.MOA.tolist()))\n",
        "input1 = Input(shape=(train_x.shape[1],))\n",
        "layer = Dense(64, activation='relu')(input1)\n",
        "layer = Dropout(0.85)(layer)\n",
        "layer = Dense(num, activation='softmax')(layer)\n",
        "model1 = Model(inputs = input1, outputs = layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ooDkEyMsNwkP"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath_mlp = '/content/'+'MLP_20_MOA_weights.hdf5'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath_mlp, monitor='val_accuracy', verbose=0, save_best_only = True,\n",
        "                mode = 'max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Dt90GZzfOBar"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gFbTVo2qkIJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f67f902d-c24e-4442-ad3a-d39b28b26e8a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 - 1s - loss: 3.0968 - accuracy: 0.0553 - val_loss: 2.9901 - val_accuracy: 0.0656 - lr: 1.0000e-04 - 1s/epoch - 63ms/step\n",
            "Epoch 2/1800\n",
            "16/16 - 0s - loss: 3.0633 - accuracy: 0.0461 - val_loss: 2.9782 - val_accuracy: 0.0656 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 3/1800\n",
            "16/16 - 0s - loss: 3.0498 - accuracy: 0.0748 - val_loss: 2.9666 - val_accuracy: 0.0738 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 4/1800\n",
            "16/16 - 0s - loss: 3.0358 - accuracy: 0.0615 - val_loss: 2.9552 - val_accuracy: 0.0820 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 5/1800\n",
            "16/16 - 0s - loss: 3.0030 - accuracy: 0.0645 - val_loss: 2.9449 - val_accuracy: 0.0984 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 6/1800\n",
            "16/16 - 0s - loss: 2.9830 - accuracy: 0.0758 - val_loss: 2.9345 - val_accuracy: 0.1148 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
            "Epoch 7/1800\n",
            "16/16 - 0s - loss: 2.9973 - accuracy: 0.0686 - val_loss: 2.9247 - val_accuracy: 0.1230 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 8/1800\n",
            "16/16 - 0s - loss: 2.9725 - accuracy: 0.0748 - val_loss: 2.9152 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 9/1800\n",
            "16/16 - 0s - loss: 2.9164 - accuracy: 0.1004 - val_loss: 2.9059 - val_accuracy: 0.1475 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
            "Epoch 10/1800\n",
            "16/16 - 0s - loss: 2.9324 - accuracy: 0.0984 - val_loss: 2.8967 - val_accuracy: 0.1639 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 11/1800\n",
            "16/16 - 0s - loss: 2.9001 - accuracy: 0.0984 - val_loss: 2.8869 - val_accuracy: 0.1885 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 12/1800\n",
            "16/16 - 0s - loss: 2.8943 - accuracy: 0.1014 - val_loss: 2.8779 - val_accuracy: 0.2131 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 13/1800\n",
            "16/16 - 0s - loss: 2.8898 - accuracy: 0.0922 - val_loss: 2.8682 - val_accuracy: 0.2377 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
            "Epoch 14/1800\n",
            "16/16 - 0s - loss: 2.8803 - accuracy: 0.1045 - val_loss: 2.8580 - val_accuracy: 0.2459 - lr: 1.0000e-04 - 78ms/epoch - 5ms/step\n",
            "Epoch 15/1800\n",
            "16/16 - 0s - loss: 2.8521 - accuracy: 0.1250 - val_loss: 2.8480 - val_accuracy: 0.2869 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 16/1800\n",
            "16/16 - 0s - loss: 2.8597 - accuracy: 0.1240 - val_loss: 2.8383 - val_accuracy: 0.2787 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 17/1800\n",
            "16/16 - 0s - loss: 2.8343 - accuracy: 0.1209 - val_loss: 2.8282 - val_accuracy: 0.2869 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 18/1800\n",
            "16/16 - 0s - loss: 2.8289 - accuracy: 0.1281 - val_loss: 2.8173 - val_accuracy: 0.2951 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 19/1800\n",
            "16/16 - 0s - loss: 2.8099 - accuracy: 0.1373 - val_loss: 2.8070 - val_accuracy: 0.3115 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 20/1800\n",
            "16/16 - 0s - loss: 2.7996 - accuracy: 0.1557 - val_loss: 2.7952 - val_accuracy: 0.3361 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
            "Epoch 21/1800\n",
            "16/16 - 0s - loss: 2.8149 - accuracy: 0.1393 - val_loss: 2.7845 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
            "Epoch 22/1800\n",
            "16/16 - 0s - loss: 2.7671 - accuracy: 0.1547 - val_loss: 2.7738 - val_accuracy: 0.3525 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 23/1800\n",
            "16/16 - 0s - loss: 2.7464 - accuracy: 0.1711 - val_loss: 2.7622 - val_accuracy: 0.3443 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 24/1800\n",
            "16/16 - 0s - loss: 2.7657 - accuracy: 0.1762 - val_loss: 2.7504 - val_accuracy: 0.3607 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 25/1800\n",
            "16/16 - 0s - loss: 2.7297 - accuracy: 0.1568 - val_loss: 2.7389 - val_accuracy: 0.3689 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
            "Epoch 26/1800\n",
            "16/16 - 0s - loss: 2.7303 - accuracy: 0.1691 - val_loss: 2.7278 - val_accuracy: 0.3689 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 27/1800\n",
            "16/16 - 0s - loss: 2.6934 - accuracy: 0.1742 - val_loss: 2.7146 - val_accuracy: 0.3852 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 28/1800\n",
            "16/16 - 0s - loss: 2.6847 - accuracy: 0.1721 - val_loss: 2.7014 - val_accuracy: 0.3934 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 29/1800\n",
            "16/16 - 0s - loss: 2.7037 - accuracy: 0.1906 - val_loss: 2.6888 - val_accuracy: 0.3934 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 30/1800\n",
            "16/16 - 0s - loss: 2.6676 - accuracy: 0.1926 - val_loss: 2.6769 - val_accuracy: 0.3934 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 31/1800\n",
            "16/16 - 0s - loss: 2.6458 - accuracy: 0.1967 - val_loss: 2.6639 - val_accuracy: 0.4016 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 32/1800\n",
            "16/16 - 0s - loss: 2.6368 - accuracy: 0.2049 - val_loss: 2.6503 - val_accuracy: 0.4180 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 33/1800\n",
            "16/16 - 0s - loss: 2.6795 - accuracy: 0.1721 - val_loss: 2.6397 - val_accuracy: 0.4180 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 34/1800\n",
            "16/16 - 0s - loss: 2.6062 - accuracy: 0.2254 - val_loss: 2.6279 - val_accuracy: 0.4180 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 35/1800\n",
            "16/16 - 0s - loss: 2.6261 - accuracy: 0.2152 - val_loss: 2.6158 - val_accuracy: 0.4262 - lr: 1.0000e-04 - 72ms/epoch - 5ms/step\n",
            "Epoch 36/1800\n",
            "16/16 - 0s - loss: 2.6131 - accuracy: 0.1926 - val_loss: 2.6038 - val_accuracy: 0.4426 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
            "Epoch 37/1800\n",
            "16/16 - 0s - loss: 2.5952 - accuracy: 0.2131 - val_loss: 2.5926 - val_accuracy: 0.4426 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
            "Epoch 38/1800\n",
            "16/16 - 0s - loss: 2.5389 - accuracy: 0.2203 - val_loss: 2.5792 - val_accuracy: 0.4508 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
            "Epoch 39/1800\n",
            "16/16 - 0s - loss: 2.5521 - accuracy: 0.2387 - val_loss: 2.5656 - val_accuracy: 0.4590 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 40/1800\n",
            "16/16 - 0s - loss: 2.5421 - accuracy: 0.2316 - val_loss: 2.5526 - val_accuracy: 0.4590 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 41/1800\n",
            "16/16 - 0s - loss: 2.5220 - accuracy: 0.2520 - val_loss: 2.5385 - val_accuracy: 0.4672 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
            "Epoch 42/1800\n",
            "16/16 - 0s - loss: 2.4992 - accuracy: 0.2520 - val_loss: 2.5259 - val_accuracy: 0.4836 - lr: 1.0000e-04 - 73ms/epoch - 5ms/step\n",
            "Epoch 43/1800\n",
            "16/16 - 0s - loss: 2.5156 - accuracy: 0.2346 - val_loss: 2.5138 - val_accuracy: 0.4918 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 44/1800\n",
            "16/16 - 0s - loss: 2.5001 - accuracy: 0.2520 - val_loss: 2.5021 - val_accuracy: 0.5082 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 45/1800\n",
            "16/16 - 0s - loss: 2.4911 - accuracy: 0.2520 - val_loss: 2.4905 - val_accuracy: 0.5246 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 46/1800\n",
            "16/16 - 0s - loss: 2.4814 - accuracy: 0.2582 - val_loss: 2.4789 - val_accuracy: 0.5164 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 47/1800\n",
            "16/16 - 0s - loss: 2.4390 - accuracy: 0.2725 - val_loss: 2.4674 - val_accuracy: 0.5164 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 48/1800\n",
            "16/16 - 0s - loss: 2.4459 - accuracy: 0.2623 - val_loss: 2.4560 - val_accuracy: 0.5164 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 49/1800\n",
            "16/16 - 0s - loss: 2.4176 - accuracy: 0.2684 - val_loss: 2.4444 - val_accuracy: 0.5164 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 50/1800\n",
            "16/16 - 0s - loss: 2.4489 - accuracy: 0.2459 - val_loss: 2.4323 - val_accuracy: 0.5246 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 51/1800\n",
            "16/16 - 0s - loss: 2.4298 - accuracy: 0.2674 - val_loss: 2.4215 - val_accuracy: 0.5328 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 52/1800\n",
            "16/16 - 0s - loss: 2.4031 - accuracy: 0.2869 - val_loss: 2.4097 - val_accuracy: 0.5328 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 53/1800\n",
            "16/16 - 0s - loss: 2.3887 - accuracy: 0.2910 - val_loss: 2.3979 - val_accuracy: 0.5328 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 54/1800\n",
            "16/16 - 0s - loss: 2.3607 - accuracy: 0.2951 - val_loss: 2.3868 - val_accuracy: 0.5410 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 55/1800\n",
            "16/16 - 0s - loss: 2.3813 - accuracy: 0.2879 - val_loss: 2.3765 - val_accuracy: 0.5574 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 56/1800\n",
            "16/16 - 0s - loss: 2.3887 - accuracy: 0.2725 - val_loss: 2.3666 - val_accuracy: 0.5656 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 57/1800\n",
            "16/16 - 0s - loss: 2.3793 - accuracy: 0.2797 - val_loss: 2.3557 - val_accuracy: 0.5656 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 58/1800\n",
            "16/16 - 0s - loss: 2.3280 - accuracy: 0.3033 - val_loss: 2.3449 - val_accuracy: 0.5738 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 59/1800\n",
            "16/16 - 0s - loss: 2.3238 - accuracy: 0.3023 - val_loss: 2.3345 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
            "Epoch 60/1800\n",
            "16/16 - 0s - loss: 2.3114 - accuracy: 0.3135 - val_loss: 2.3240 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 61/1800\n",
            "16/16 - 0s - loss: 2.2941 - accuracy: 0.3094 - val_loss: 2.3139 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 62/1800\n",
            "16/16 - 0s - loss: 2.2914 - accuracy: 0.3135 - val_loss: 2.3035 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 63/1800\n",
            "16/16 - 0s - loss: 2.2885 - accuracy: 0.2992 - val_loss: 2.2932 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 64/1800\n",
            "16/16 - 0s - loss: 2.2750 - accuracy: 0.3135 - val_loss: 2.2822 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 65/1800\n",
            "16/16 - 0s - loss: 2.3000 - accuracy: 0.3391 - val_loss: 2.2725 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 66/1800\n",
            "16/16 - 0s - loss: 2.2734 - accuracy: 0.3094 - val_loss: 2.2631 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 67/1800\n",
            "16/16 - 0s - loss: 2.2602 - accuracy: 0.3350 - val_loss: 2.2531 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 68/1800\n",
            "16/16 - 0s - loss: 2.2197 - accuracy: 0.3340 - val_loss: 2.2430 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 69/1800\n",
            "16/16 - 0s - loss: 2.2214 - accuracy: 0.3248 - val_loss: 2.2343 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 70/1800\n",
            "16/16 - 0s - loss: 2.2176 - accuracy: 0.3115 - val_loss: 2.2248 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 71/1800\n",
            "16/16 - 0s - loss: 2.2165 - accuracy: 0.3207 - val_loss: 2.2160 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 72/1800\n",
            "16/16 - 0s - loss: 2.2496 - accuracy: 0.3125 - val_loss: 2.2074 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 73/1800\n",
            "16/16 - 0s - loss: 2.2071 - accuracy: 0.3197 - val_loss: 2.1992 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 74/1800\n",
            "16/16 - 0s - loss: 2.1585 - accuracy: 0.3432 - val_loss: 2.1898 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 75/1800\n",
            "16/16 - 0s - loss: 2.1452 - accuracy: 0.3586 - val_loss: 2.1797 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 76/1800\n",
            "16/16 - 0s - loss: 2.1366 - accuracy: 0.3412 - val_loss: 2.1693 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 77/1800\n",
            "16/16 - 0s - loss: 2.1525 - accuracy: 0.3525 - val_loss: 2.1601 - val_accuracy: 0.5738 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 78/1800\n",
            "16/16 - 0s - loss: 2.0822 - accuracy: 0.3658 - val_loss: 2.1512 - val_accuracy: 0.5738 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 79/1800\n",
            "16/16 - 0s - loss: 2.1157 - accuracy: 0.3422 - val_loss: 2.1426 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 80/1800\n",
            "16/16 - 0s - loss: 2.0643 - accuracy: 0.3801 - val_loss: 2.1340 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 81/1800\n",
            "16/16 - 0s - loss: 2.1381 - accuracy: 0.3258 - val_loss: 2.1268 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 82/1800\n",
            "16/16 - 0s - loss: 2.1757 - accuracy: 0.3391 - val_loss: 2.1205 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 83/1800\n",
            "16/16 - 0s - loss: 2.0950 - accuracy: 0.3473 - val_loss: 2.1129 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 84/1800\n",
            "16/16 - 0s - loss: 2.1156 - accuracy: 0.3494 - val_loss: 2.1053 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 85/1800\n",
            "16/16 - 0s - loss: 2.0992 - accuracy: 0.3627 - val_loss: 2.0981 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 86/1800\n",
            "16/16 - 0s - loss: 2.0258 - accuracy: 0.3832 - val_loss: 2.0889 - val_accuracy: 0.5820 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 87/1800\n",
            "16/16 - 0s - loss: 2.0226 - accuracy: 0.3760 - val_loss: 2.0798 - val_accuracy: 0.5984 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 88/1800\n",
            "16/16 - 0s - loss: 2.0407 - accuracy: 0.3730 - val_loss: 2.0718 - val_accuracy: 0.6066 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 89/1800\n",
            "16/16 - 0s - loss: 2.0471 - accuracy: 0.3770 - val_loss: 2.0637 - val_accuracy: 0.6230 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 90/1800\n",
            "16/16 - 0s - loss: 2.0283 - accuracy: 0.3781 - val_loss: 2.0558 - val_accuracy: 0.6148 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 91/1800\n",
            "16/16 - 0s - loss: 2.0089 - accuracy: 0.3904 - val_loss: 2.0492 - val_accuracy: 0.6066 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 92/1800\n",
            "16/16 - 0s - loss: 2.0322 - accuracy: 0.3648 - val_loss: 2.0437 - val_accuracy: 0.6148 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 93/1800\n",
            "16/16 - 0s - loss: 1.9866 - accuracy: 0.3893 - val_loss: 2.0362 - val_accuracy: 0.6148 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 94/1800\n",
            "16/16 - 0s - loss: 2.0356 - accuracy: 0.3648 - val_loss: 2.0287 - val_accuracy: 0.6230 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 95/1800\n",
            "16/16 - 0s - loss: 2.0373 - accuracy: 0.3668 - val_loss: 2.0203 - val_accuracy: 0.6230 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 96/1800\n",
            "16/16 - 0s - loss: 1.9754 - accuracy: 0.3832 - val_loss: 2.0136 - val_accuracy: 0.6230 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 97/1800\n",
            "16/16 - 0s - loss: 1.9874 - accuracy: 0.3924 - val_loss: 2.0083 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 98/1800\n",
            "16/16 - 0s - loss: 1.9723 - accuracy: 0.3986 - val_loss: 2.0026 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 99/1800\n",
            "16/16 - 0s - loss: 1.9652 - accuracy: 0.3996 - val_loss: 1.9957 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 100/1800\n",
            "16/16 - 0s - loss: 1.9904 - accuracy: 0.3863 - val_loss: 1.9883 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 101/1800\n",
            "16/16 - 0s - loss: 1.9060 - accuracy: 0.4078 - val_loss: 1.9810 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 102/1800\n",
            "16/16 - 0s - loss: 1.9076 - accuracy: 0.4027 - val_loss: 1.9737 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 103/1800\n",
            "16/16 - 0s - loss: 1.9312 - accuracy: 0.3975 - val_loss: 1.9665 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 104/1800\n",
            "16/16 - 0s - loss: 1.9059 - accuracy: 0.4170 - val_loss: 1.9595 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 105/1800\n",
            "16/16 - 0s - loss: 1.9499 - accuracy: 0.3934 - val_loss: 1.9536 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 106/1800\n",
            "16/16 - 0s - loss: 1.9391 - accuracy: 0.3996 - val_loss: 1.9481 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 107/1800\n",
            "16/16 - 0s - loss: 1.9514 - accuracy: 0.4006 - val_loss: 1.9426 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 108/1800\n",
            "16/16 - 0s - loss: 1.9027 - accuracy: 0.4139 - val_loss: 1.9363 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 109/1800\n",
            "16/16 - 0s - loss: 1.9072 - accuracy: 0.4037 - val_loss: 1.9301 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 110/1800\n",
            "16/16 - 0s - loss: 1.8534 - accuracy: 0.4283 - val_loss: 1.9237 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 111/1800\n",
            "16/16 - 0s - loss: 1.8671 - accuracy: 0.4191 - val_loss: 1.9177 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 112/1800\n",
            "16/16 - 0s - loss: 1.8102 - accuracy: 0.4406 - val_loss: 1.9111 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 113/1800\n",
            "16/16 - 0s - loss: 1.8460 - accuracy: 0.4160 - val_loss: 1.9053 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 114/1800\n",
            "16/16 - 0s - loss: 1.9067 - accuracy: 0.3945 - val_loss: 1.9010 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 115/1800\n",
            "16/16 - 0s - loss: 1.8338 - accuracy: 0.4508 - val_loss: 1.8960 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 116/1800\n",
            "16/16 - 0s - loss: 1.8699 - accuracy: 0.4365 - val_loss: 1.8902 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
            "Epoch 117/1800\n",
            "16/16 - 0s - loss: 1.8370 - accuracy: 0.4436 - val_loss: 1.8842 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
            "Epoch 118/1800\n",
            "16/16 - 0s - loss: 1.8543 - accuracy: 0.4139 - val_loss: 1.8787 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 77ms/epoch - 5ms/step\n",
            "Epoch 119/1800\n",
            "16/16 - 0s - loss: 1.8418 - accuracy: 0.4344 - val_loss: 1.8728 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 120/1800\n",
            "16/16 - 0s - loss: 1.8160 - accuracy: 0.4375 - val_loss: 1.8671 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 121/1800\n",
            "16/16 - 0s - loss: 1.8669 - accuracy: 0.4252 - val_loss: 1.8618 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 122/1800\n",
            "16/16 - 0s - loss: 1.7998 - accuracy: 0.4693 - val_loss: 1.8570 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 123/1800\n",
            "16/16 - 0s - loss: 1.7767 - accuracy: 0.4590 - val_loss: 1.8506 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 124/1800\n",
            "16/16 - 0s - loss: 1.7791 - accuracy: 0.4457 - val_loss: 1.8443 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 125/1800\n",
            "16/16 - 0s - loss: 1.7675 - accuracy: 0.4355 - val_loss: 1.8394 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 126/1800\n",
            "16/16 - 0s - loss: 1.8495 - accuracy: 0.4160 - val_loss: 1.8344 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 127/1800\n",
            "16/16 - 0s - loss: 1.8003 - accuracy: 0.4375 - val_loss: 1.8294 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 72ms/epoch - 4ms/step\n",
            "Epoch 128/1800\n",
            "16/16 - 0s - loss: 1.7160 - accuracy: 0.4785 - val_loss: 1.8238 - val_accuracy: 0.6311 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 129/1800\n",
            "16/16 - 0s - loss: 1.7387 - accuracy: 0.4682 - val_loss: 1.8191 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 130/1800\n",
            "16/16 - 0s - loss: 1.7869 - accuracy: 0.4385 - val_loss: 1.8144 - val_accuracy: 0.6393 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 131/1800\n",
            "16/16 - 0s - loss: 1.7376 - accuracy: 0.4734 - val_loss: 1.8088 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 132/1800\n",
            "16/16 - 0s - loss: 1.7276 - accuracy: 0.4631 - val_loss: 1.8035 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 133/1800\n",
            "16/16 - 0s - loss: 1.7398 - accuracy: 0.4498 - val_loss: 1.7993 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 134/1800\n",
            "16/16 - 0s - loss: 1.7205 - accuracy: 0.4590 - val_loss: 1.7941 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 135/1800\n",
            "16/16 - 0s - loss: 1.7960 - accuracy: 0.4416 - val_loss: 1.7904 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 136/1800\n",
            "16/16 - 0s - loss: 1.7422 - accuracy: 0.4529 - val_loss: 1.7849 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 137/1800\n",
            "16/16 - 0s - loss: 1.6931 - accuracy: 0.4539 - val_loss: 1.7797 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 74ms/epoch - 5ms/step\n",
            "Epoch 138/1800\n",
            "16/16 - 0s - loss: 1.7223 - accuracy: 0.4611 - val_loss: 1.7750 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 76ms/epoch - 5ms/step\n",
            "Epoch 139/1800\n",
            "16/16 - 0s - loss: 1.7317 - accuracy: 0.4549 - val_loss: 1.7709 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 67ms/epoch - 4ms/step\n",
            "Epoch 140/1800\n",
            "16/16 - 0s - loss: 1.6762 - accuracy: 0.4641 - val_loss: 1.7661 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 141/1800\n",
            "16/16 - 0s - loss: 1.7437 - accuracy: 0.4498 - val_loss: 1.7610 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 142/1800\n",
            "16/16 - 0s - loss: 1.7009 - accuracy: 0.4703 - val_loss: 1.7566 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 143/1800\n",
            "16/16 - 0s - loss: 1.7087 - accuracy: 0.4816 - val_loss: 1.7516 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 144/1800\n",
            "16/16 - 0s - loss: 1.6618 - accuracy: 0.4600 - val_loss: 1.7473 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 145/1800\n",
            "16/16 - 0s - loss: 1.6634 - accuracy: 0.4631 - val_loss: 1.7440 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 146/1800\n",
            "16/16 - 0s - loss: 1.6659 - accuracy: 0.4744 - val_loss: 1.7407 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 147/1800\n",
            "16/16 - 0s - loss: 1.6738 - accuracy: 0.4764 - val_loss: 1.7369 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 148/1800\n",
            "16/16 - 0s - loss: 1.6258 - accuracy: 0.4764 - val_loss: 1.7320 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 149/1800\n",
            "16/16 - 0s - loss: 1.6667 - accuracy: 0.4570 - val_loss: 1.7268 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 150/1800\n",
            "16/16 - 0s - loss: 1.6586 - accuracy: 0.4703 - val_loss: 1.7222 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 151/1800\n",
            "16/16 - 0s - loss: 1.6487 - accuracy: 0.4898 - val_loss: 1.7173 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 152/1800\n",
            "16/16 - 0s - loss: 1.6591 - accuracy: 0.4693 - val_loss: 1.7136 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 153/1800\n",
            "16/16 - 0s - loss: 1.6958 - accuracy: 0.4570 - val_loss: 1.7108 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 154/1800\n",
            "16/16 - 0s - loss: 1.6637 - accuracy: 0.4682 - val_loss: 1.7078 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 155/1800\n",
            "16/16 - 0s - loss: 1.6431 - accuracy: 0.4703 - val_loss: 1.7039 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 156/1800\n",
            "16/16 - 0s - loss: 1.6266 - accuracy: 0.5000 - val_loss: 1.6998 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 157/1800\n",
            "16/16 - 0s - loss: 1.6450 - accuracy: 0.4744 - val_loss: 1.6953 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 158/1800\n",
            "16/16 - 0s - loss: 1.5965 - accuracy: 0.5092 - val_loss: 1.6913 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 159/1800\n",
            "16/16 - 0s - loss: 1.6338 - accuracy: 0.4857 - val_loss: 1.6871 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 160/1800\n",
            "16/16 - 0s - loss: 1.5946 - accuracy: 0.5082 - val_loss: 1.6829 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 161/1800\n",
            "16/16 - 0s - loss: 1.5866 - accuracy: 0.5061 - val_loss: 1.6792 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 162/1800\n",
            "16/16 - 0s - loss: 1.5685 - accuracy: 0.4959 - val_loss: 1.6751 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 163/1800\n",
            "16/16 - 0s - loss: 1.6472 - accuracy: 0.4754 - val_loss: 1.6714 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 164/1800\n",
            "16/16 - 0s - loss: 1.6199 - accuracy: 0.4641 - val_loss: 1.6683 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 165/1800\n",
            "16/16 - 0s - loss: 1.5606 - accuracy: 0.4918 - val_loss: 1.6648 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 166/1800\n",
            "16/16 - 0s - loss: 1.6250 - accuracy: 0.4877 - val_loss: 1.6610 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 167/1800\n",
            "16/16 - 0s - loss: 1.5812 - accuracy: 0.4908 - val_loss: 1.6559 - val_accuracy: 0.6475 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 168/1800\n",
            "16/16 - 0s - loss: 1.6025 - accuracy: 0.4980 - val_loss: 1.6522 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 169/1800\n",
            "16/16 - 0s - loss: 1.5774 - accuracy: 0.5020 - val_loss: 1.6499 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 170/1800\n",
            "16/16 - 0s - loss: 1.5244 - accuracy: 0.5113 - val_loss: 1.6462 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 171/1800\n",
            "16/16 - 0s - loss: 1.5613 - accuracy: 0.5010 - val_loss: 1.6424 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 172/1800\n",
            "16/16 - 0s - loss: 1.5779 - accuracy: 0.4918 - val_loss: 1.6388 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 173/1800\n",
            "16/16 - 0s - loss: 1.5708 - accuracy: 0.4887 - val_loss: 1.6344 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 174/1800\n",
            "16/16 - 0s - loss: 1.5874 - accuracy: 0.4826 - val_loss: 1.6313 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 175/1800\n",
            "16/16 - 0s - loss: 1.5223 - accuracy: 0.5287 - val_loss: 1.6288 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 176/1800\n",
            "16/16 - 0s - loss: 1.4954 - accuracy: 0.5379 - val_loss: 1.6250 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 177/1800\n",
            "16/16 - 0s - loss: 1.5435 - accuracy: 0.5256 - val_loss: 1.6207 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 178/1800\n",
            "16/16 - 0s - loss: 1.5101 - accuracy: 0.5092 - val_loss: 1.6169 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 179/1800\n",
            "16/16 - 0s - loss: 1.5144 - accuracy: 0.5236 - val_loss: 1.6129 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 180/1800\n",
            "16/16 - 0s - loss: 1.5233 - accuracy: 0.5102 - val_loss: 1.6093 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 181/1800\n",
            "16/16 - 0s - loss: 1.5413 - accuracy: 0.4969 - val_loss: 1.6065 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 182/1800\n",
            "16/16 - 0s - loss: 1.5041 - accuracy: 0.5143 - val_loss: 1.6033 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 183/1800\n",
            "16/16 - 0s - loss: 1.5254 - accuracy: 0.5174 - val_loss: 1.6001 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 184/1800\n",
            "16/16 - 0s - loss: 1.5536 - accuracy: 0.4908 - val_loss: 1.5970 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 185/1800\n",
            "16/16 - 0s - loss: 1.4318 - accuracy: 0.5471 - val_loss: 1.5933 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 186/1800\n",
            "16/16 - 0s - loss: 1.4638 - accuracy: 0.5154 - val_loss: 1.5893 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 187/1800\n",
            "16/16 - 0s - loss: 1.5149 - accuracy: 0.5143 - val_loss: 1.5857 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 188/1800\n",
            "16/16 - 0s - loss: 1.5284 - accuracy: 0.5348 - val_loss: 1.5821 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 189/1800\n",
            "16/16 - 0s - loss: 1.5127 - accuracy: 0.5082 - val_loss: 1.5792 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 190/1800\n",
            "16/16 - 0s - loss: 1.5079 - accuracy: 0.5287 - val_loss: 1.5762 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 191/1800\n",
            "16/16 - 0s - loss: 1.5003 - accuracy: 0.5102 - val_loss: 1.5741 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 192/1800\n",
            "16/16 - 0s - loss: 1.4881 - accuracy: 0.5389 - val_loss: 1.5710 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 193/1800\n",
            "16/16 - 0s - loss: 1.4751 - accuracy: 0.5082 - val_loss: 1.5682 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 194/1800\n",
            "16/16 - 0s - loss: 1.5210 - accuracy: 0.5236 - val_loss: 1.5652 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 195/1800\n",
            "16/16 - 0s - loss: 1.4742 - accuracy: 0.5020 - val_loss: 1.5621 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 196/1800\n",
            "16/16 - 0s - loss: 1.5129 - accuracy: 0.5133 - val_loss: 1.5586 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 197/1800\n",
            "16/16 - 0s - loss: 1.4513 - accuracy: 0.5338 - val_loss: 1.5555 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 198/1800\n",
            "16/16 - 0s - loss: 1.4838 - accuracy: 0.5184 - val_loss: 1.5527 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 199/1800\n",
            "16/16 - 0s - loss: 1.4307 - accuracy: 0.5389 - val_loss: 1.5487 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 200/1800\n",
            "16/16 - 0s - loss: 1.4675 - accuracy: 0.5246 - val_loss: 1.5448 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 201/1800\n",
            "16/16 - 0s - loss: 1.4428 - accuracy: 0.5430 - val_loss: 1.5416 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 202/1800\n",
            "16/16 - 0s - loss: 1.4192 - accuracy: 0.5574 - val_loss: 1.5383 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 203/1800\n",
            "16/16 - 0s - loss: 1.4155 - accuracy: 0.5512 - val_loss: 1.5357 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 204/1800\n",
            "16/16 - 0s - loss: 1.3984 - accuracy: 0.5461 - val_loss: 1.5332 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 205/1800\n",
            "16/16 - 0s - loss: 1.4362 - accuracy: 0.5348 - val_loss: 1.5311 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 206/1800\n",
            "16/16 - 0s - loss: 1.4502 - accuracy: 0.5297 - val_loss: 1.5284 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 207/1800\n",
            "16/16 - 0s - loss: 1.4413 - accuracy: 0.5379 - val_loss: 1.5257 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 208/1800\n",
            "16/16 - 0s - loss: 1.3977 - accuracy: 0.5512 - val_loss: 1.5234 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 209/1800\n",
            "16/16 - 0s - loss: 1.4083 - accuracy: 0.5318 - val_loss: 1.5204 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 210/1800\n",
            "16/16 - 0s - loss: 1.4372 - accuracy: 0.5287 - val_loss: 1.5177 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 211/1800\n",
            "16/16 - 0s - loss: 1.3987 - accuracy: 0.5451 - val_loss: 1.5149 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 212/1800\n",
            "16/16 - 0s - loss: 1.4099 - accuracy: 0.5533 - val_loss: 1.5125 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 213/1800\n",
            "16/16 - 0s - loss: 1.3721 - accuracy: 0.5676 - val_loss: 1.5094 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 214/1800\n",
            "16/16 - 0s - loss: 1.3776 - accuracy: 0.5533 - val_loss: 1.5068 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 215/1800\n",
            "16/16 - 0s - loss: 1.4001 - accuracy: 0.5523 - val_loss: 1.5045 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 216/1800\n",
            "16/16 - 0s - loss: 1.4265 - accuracy: 0.5379 - val_loss: 1.5019 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 217/1800\n",
            "16/16 - 0s - loss: 1.4255 - accuracy: 0.5389 - val_loss: 1.4994 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 218/1800\n",
            "16/16 - 0s - loss: 1.3967 - accuracy: 0.5482 - val_loss: 1.4969 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 219/1800\n",
            "16/16 - 0s - loss: 1.3988 - accuracy: 0.5369 - val_loss: 1.4938 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 220/1800\n",
            "16/16 - 0s - loss: 1.3379 - accuracy: 0.5656 - val_loss: 1.4915 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 221/1800\n",
            "16/16 - 0s - loss: 1.3517 - accuracy: 0.5686 - val_loss: 1.4899 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 222/1800\n",
            "16/16 - 0s - loss: 1.3798 - accuracy: 0.5492 - val_loss: 1.4874 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 223/1800\n",
            "16/16 - 0s - loss: 1.3278 - accuracy: 0.5758 - val_loss: 1.4856 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 224/1800\n",
            "16/16 - 0s - loss: 1.3478 - accuracy: 0.5502 - val_loss: 1.4831 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 225/1800\n",
            "16/16 - 0s - loss: 1.3633 - accuracy: 0.5410 - val_loss: 1.4807 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 226/1800\n",
            "16/16 - 0s - loss: 1.3791 - accuracy: 0.5594 - val_loss: 1.4786 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 75ms/epoch - 5ms/step\n",
            "Epoch 227/1800\n",
            "16/16 - 0s - loss: 1.3746 - accuracy: 0.5318 - val_loss: 1.4764 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 228/1800\n",
            "16/16 - 0s - loss: 1.3524 - accuracy: 0.5615 - val_loss: 1.4738 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 229/1800\n",
            "16/16 - 0s - loss: 1.3695 - accuracy: 0.5584 - val_loss: 1.4711 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 230/1800\n",
            "16/16 - 0s - loss: 1.3895 - accuracy: 0.5430 - val_loss: 1.4691 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 231/1800\n",
            "16/16 - 0s - loss: 1.3572 - accuracy: 0.5502 - val_loss: 1.4666 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 232/1800\n",
            "16/16 - 0s - loss: 1.3479 - accuracy: 0.5686 - val_loss: 1.4636 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 233/1800\n",
            "16/16 - 0s - loss: 1.3060 - accuracy: 0.5727 - val_loss: 1.4615 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 234/1800\n",
            "16/16 - 0s - loss: 1.3786 - accuracy: 0.5553 - val_loss: 1.4594 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 235/1800\n",
            "16/16 - 0s - loss: 1.3063 - accuracy: 0.5594 - val_loss: 1.4577 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 236/1800\n",
            "16/16 - 0s - loss: 1.3858 - accuracy: 0.5471 - val_loss: 1.4561 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 237/1800\n",
            "16/16 - 0s - loss: 1.3294 - accuracy: 0.5543 - val_loss: 1.4548 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 238/1800\n",
            "16/16 - 0s - loss: 1.3113 - accuracy: 0.5697 - val_loss: 1.4520 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 239/1800\n",
            "16/16 - 0s - loss: 1.3300 - accuracy: 0.5799 - val_loss: 1.4505 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
            "Epoch 240/1800\n",
            "16/16 - 0s - loss: 1.2858 - accuracy: 0.6004 - val_loss: 1.4481 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
            "Epoch 241/1800\n",
            "16/16 - 0s - loss: 1.2918 - accuracy: 0.5686 - val_loss: 1.4447 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 242/1800\n",
            "16/16 - 0s - loss: 1.3586 - accuracy: 0.5400 - val_loss: 1.4427 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 243/1800\n",
            "16/16 - 0s - loss: 1.3358 - accuracy: 0.5584 - val_loss: 1.4407 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 244/1800\n",
            "16/16 - 0s - loss: 1.3123 - accuracy: 0.5707 - val_loss: 1.4381 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 245/1800\n",
            "16/16 - 0s - loss: 1.2652 - accuracy: 0.5922 - val_loss: 1.4364 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 246/1800\n",
            "16/16 - 0s - loss: 1.3070 - accuracy: 0.5799 - val_loss: 1.4350 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 247/1800\n",
            "16/16 - 0s - loss: 1.2696 - accuracy: 0.5666 - val_loss: 1.4329 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 248/1800\n",
            "16/16 - 0s - loss: 1.2922 - accuracy: 0.5830 - val_loss: 1.4304 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 63ms/epoch - 4ms/step\n",
            "Epoch 249/1800\n",
            "16/16 - 0s - loss: 1.3081 - accuracy: 0.5717 - val_loss: 1.4284 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 250/1800\n",
            "16/16 - 0s - loss: 1.2972 - accuracy: 0.5768 - val_loss: 1.4272 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 251/1800\n",
            "16/16 - 0s - loss: 1.3189 - accuracy: 0.5471 - val_loss: 1.4247 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 252/1800\n",
            "16/16 - 0s - loss: 1.2856 - accuracy: 0.5748 - val_loss: 1.4229 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 253/1800\n",
            "16/16 - 0s - loss: 1.2776 - accuracy: 0.5768 - val_loss: 1.4211 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 254/1800\n",
            "16/16 - 0s - loss: 1.2848 - accuracy: 0.5564 - val_loss: 1.4193 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 255/1800\n",
            "16/16 - 0s - loss: 1.2580 - accuracy: 0.5820 - val_loss: 1.4171 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 256/1800\n",
            "16/16 - 0s - loss: 1.2717 - accuracy: 0.5564 - val_loss: 1.4154 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 257/1800\n",
            "16/16 - 0s - loss: 1.2542 - accuracy: 0.5779 - val_loss: 1.4127 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 258/1800\n",
            "16/16 - 0s - loss: 1.2201 - accuracy: 0.5973 - val_loss: 1.4099 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 259/1800\n",
            "16/16 - 0s - loss: 1.2848 - accuracy: 0.5850 - val_loss: 1.4075 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 260/1800\n",
            "16/16 - 0s - loss: 1.2862 - accuracy: 0.5676 - val_loss: 1.4059 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 261/1800\n",
            "16/16 - 0s - loss: 1.2579 - accuracy: 0.5912 - val_loss: 1.4048 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 262/1800\n",
            "16/16 - 0s - loss: 1.2938 - accuracy: 0.5840 - val_loss: 1.4034 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 263/1800\n",
            "16/16 - 0s - loss: 1.2840 - accuracy: 0.5820 - val_loss: 1.4022 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 264/1800\n",
            "16/16 - 0s - loss: 1.2757 - accuracy: 0.5697 - val_loss: 1.4007 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 265/1800\n",
            "16/16 - 0s - loss: 1.2456 - accuracy: 0.5789 - val_loss: 1.3989 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 266/1800\n",
            "16/16 - 0s - loss: 1.2506 - accuracy: 0.5789 - val_loss: 1.3974 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 267/1800\n",
            "16/16 - 0s - loss: 1.2731 - accuracy: 0.5881 - val_loss: 1.3952 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 268/1800\n",
            "16/16 - 0s - loss: 1.2039 - accuracy: 0.5984 - val_loss: 1.3933 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 269/1800\n",
            "16/16 - 0s - loss: 1.2720 - accuracy: 0.5666 - val_loss: 1.3918 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 270/1800\n",
            "16/16 - 0s - loss: 1.2186 - accuracy: 0.5809 - val_loss: 1.3901 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 271/1800\n",
            "16/16 - 0s - loss: 1.2575 - accuracy: 0.5758 - val_loss: 1.3889 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 272/1800\n",
            "16/16 - 0s - loss: 1.2780 - accuracy: 0.5727 - val_loss: 1.3869 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 273/1800\n",
            "16/16 - 0s - loss: 1.2346 - accuracy: 0.5809 - val_loss: 1.3851 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 274/1800\n",
            "16/16 - 0s - loss: 1.1946 - accuracy: 0.5850 - val_loss: 1.3832 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 275/1800\n",
            "16/16 - 0s - loss: 1.1961 - accuracy: 0.6086 - val_loss: 1.3823 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 276/1800\n",
            "16/16 - 0s - loss: 1.1866 - accuracy: 0.5984 - val_loss: 1.3806 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 277/1800\n",
            "16/16 - 0s - loss: 1.2545 - accuracy: 0.5564 - val_loss: 1.3780 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 278/1800\n",
            "16/16 - 0s - loss: 1.2470 - accuracy: 0.5840 - val_loss: 1.3760 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 279/1800\n",
            "16/16 - 0s - loss: 1.2265 - accuracy: 0.5635 - val_loss: 1.3740 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 280/1800\n",
            "16/16 - 0s - loss: 1.2270 - accuracy: 0.5717 - val_loss: 1.3730 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 281/1800\n",
            "16/16 - 0s - loss: 1.2394 - accuracy: 0.5912 - val_loss: 1.3715 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 282/1800\n",
            "16/16 - 0s - loss: 1.1507 - accuracy: 0.6352 - val_loss: 1.3694 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 283/1800\n",
            "16/16 - 0s - loss: 1.1668 - accuracy: 0.6086 - val_loss: 1.3673 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 284/1800\n",
            "16/16 - 0s - loss: 1.2046 - accuracy: 0.6025 - val_loss: 1.3655 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 285/1800\n",
            "16/16 - 0s - loss: 1.1999 - accuracy: 0.5973 - val_loss: 1.3645 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 286/1800\n",
            "16/16 - 0s - loss: 1.2501 - accuracy: 0.5666 - val_loss: 1.3638 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 62ms/epoch - 4ms/step\n",
            "Epoch 287/1800\n",
            "16/16 - 0s - loss: 1.1886 - accuracy: 0.5963 - val_loss: 1.3622 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 288/1800\n",
            "16/16 - 0s - loss: 1.2417 - accuracy: 0.5758 - val_loss: 1.3610 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 289/1800\n",
            "16/16 - 0s - loss: 1.2003 - accuracy: 0.6066 - val_loss: 1.3596 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 290/1800\n",
            "16/16 - 0s - loss: 1.1828 - accuracy: 0.6025 - val_loss: 1.3577 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 291/1800\n",
            "16/16 - 0s - loss: 1.1907 - accuracy: 0.6178 - val_loss: 1.3565 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 292/1800\n",
            "16/16 - 0s - loss: 1.1860 - accuracy: 0.6076 - val_loss: 1.3551 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 293/1800\n",
            "16/16 - 0s - loss: 1.2045 - accuracy: 0.5973 - val_loss: 1.3540 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 294/1800\n",
            "16/16 - 0s - loss: 1.2007 - accuracy: 0.5994 - val_loss: 1.3532 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 295/1800\n",
            "16/16 - 0s - loss: 1.1419 - accuracy: 0.6086 - val_loss: 1.3517 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 296/1800\n",
            "16/16 - 0s - loss: 1.1896 - accuracy: 0.5922 - val_loss: 1.3504 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 297/1800\n",
            "16/16 - 0s - loss: 1.1166 - accuracy: 0.6158 - val_loss: 1.3488 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 298/1800\n",
            "16/16 - 0s - loss: 1.1888 - accuracy: 0.6014 - val_loss: 1.3469 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 299/1800\n",
            "16/16 - 0s - loss: 1.2120 - accuracy: 0.5861 - val_loss: 1.3455 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 300/1800\n",
            "16/16 - 0s - loss: 1.1410 - accuracy: 0.6096 - val_loss: 1.3441 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 301/1800\n",
            "16/16 - 0s - loss: 1.1331 - accuracy: 0.6250 - val_loss: 1.3419 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 302/1800\n",
            "16/16 - 0s - loss: 1.2002 - accuracy: 0.6076 - val_loss: 1.3409 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 303/1800\n",
            "16/16 - 0s - loss: 1.1702 - accuracy: 0.6025 - val_loss: 1.3400 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 304/1800\n",
            "16/16 - 0s - loss: 1.1827 - accuracy: 0.6025 - val_loss: 1.3390 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 305/1800\n",
            "16/16 - 0s - loss: 1.1380 - accuracy: 0.6055 - val_loss: 1.3373 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 306/1800\n",
            "16/16 - 0s - loss: 1.1137 - accuracy: 0.6301 - val_loss: 1.3359 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 307/1800\n",
            "16/16 - 0s - loss: 1.1909 - accuracy: 0.5932 - val_loss: 1.3349 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 308/1800\n",
            "16/16 - 0s - loss: 1.1260 - accuracy: 0.6240 - val_loss: 1.3335 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 309/1800\n",
            "16/16 - 0s - loss: 1.1472 - accuracy: 0.6189 - val_loss: 1.3313 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 310/1800\n",
            "16/16 - 0s - loss: 1.1281 - accuracy: 0.6240 - val_loss: 1.3301 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 311/1800\n",
            "16/16 - 0s - loss: 1.1708 - accuracy: 0.6168 - val_loss: 1.3294 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 312/1800\n",
            "16/16 - 0s - loss: 1.1452 - accuracy: 0.6209 - val_loss: 1.3284 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 313/1800\n",
            "16/16 - 0s - loss: 1.1739 - accuracy: 0.6035 - val_loss: 1.3274 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 314/1800\n",
            "16/16 - 0s - loss: 1.1874 - accuracy: 0.5994 - val_loss: 1.3265 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 315/1800\n",
            "16/16 - 0s - loss: 1.1232 - accuracy: 0.6414 - val_loss: 1.3255 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 316/1800\n",
            "16/16 - 0s - loss: 1.0931 - accuracy: 0.6311 - val_loss: 1.3237 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 317/1800\n",
            "16/16 - 0s - loss: 1.1394 - accuracy: 0.6066 - val_loss: 1.3227 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 318/1800\n",
            "16/16 - 0s - loss: 1.0516 - accuracy: 0.6537 - val_loss: 1.3217 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 319/1800\n",
            "16/16 - 0s - loss: 1.1277 - accuracy: 0.6127 - val_loss: 1.3196 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 320/1800\n",
            "16/16 - 0s - loss: 1.0627 - accuracy: 0.6383 - val_loss: 1.3179 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 321/1800\n",
            "16/16 - 0s - loss: 1.1555 - accuracy: 0.5953 - val_loss: 1.3167 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 322/1800\n",
            "16/16 - 0s - loss: 1.1441 - accuracy: 0.6373 - val_loss: 1.3159 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 323/1800\n",
            "16/16 - 0s - loss: 1.1559 - accuracy: 0.5943 - val_loss: 1.3155 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 324/1800\n",
            "16/16 - 0s - loss: 1.1037 - accuracy: 0.6291 - val_loss: 1.3150 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 325/1800\n",
            "16/16 - 0s - loss: 1.1181 - accuracy: 0.6260 - val_loss: 1.3138 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 326/1800\n",
            "16/16 - 0s - loss: 1.1186 - accuracy: 0.6086 - val_loss: 1.3129 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 327/1800\n",
            "16/16 - 0s - loss: 1.1143 - accuracy: 0.6117 - val_loss: 1.3122 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 328/1800\n",
            "16/16 - 0s - loss: 1.1018 - accuracy: 0.6311 - val_loss: 1.3110 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 329/1800\n",
            "16/16 - 0s - loss: 1.1024 - accuracy: 0.6260 - val_loss: 1.3098 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 330/1800\n",
            "16/16 - 0s - loss: 1.1264 - accuracy: 0.6137 - val_loss: 1.3088 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 331/1800\n",
            "16/16 - 0s - loss: 1.1130 - accuracy: 0.6055 - val_loss: 1.3082 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 332/1800\n",
            "16/16 - 0s - loss: 1.1180 - accuracy: 0.6158 - val_loss: 1.3075 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 333/1800\n",
            "16/16 - 0s - loss: 1.0991 - accuracy: 0.6250 - val_loss: 1.3063 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 334/1800\n",
            "16/16 - 0s - loss: 1.1037 - accuracy: 0.6424 - val_loss: 1.3057 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 335/1800\n",
            "16/16 - 0s - loss: 1.1275 - accuracy: 0.6004 - val_loss: 1.3046 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 336/1800\n",
            "16/16 - 0s - loss: 1.0934 - accuracy: 0.6178 - val_loss: 1.3039 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 337/1800\n",
            "16/16 - 0s - loss: 1.0781 - accuracy: 0.6363 - val_loss: 1.3023 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 338/1800\n",
            "16/16 - 0s - loss: 1.0901 - accuracy: 0.6373 - val_loss: 1.3016 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 339/1800\n",
            "16/16 - 0s - loss: 1.0952 - accuracy: 0.6301 - val_loss: 1.3005 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 340/1800\n",
            "16/16 - 0s - loss: 1.0693 - accuracy: 0.6383 - val_loss: 1.2991 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 341/1800\n",
            "16/16 - 0s - loss: 1.1098 - accuracy: 0.6240 - val_loss: 1.2979 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 342/1800\n",
            "16/16 - 0s - loss: 1.0820 - accuracy: 0.6260 - val_loss: 1.2969 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 343/1800\n",
            "16/16 - 0s - loss: 1.0631 - accuracy: 0.6301 - val_loss: 1.2961 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 344/1800\n",
            "16/16 - 0s - loss: 1.0636 - accuracy: 0.6270 - val_loss: 1.2953 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 345/1800\n",
            "16/16 - 0s - loss: 1.0513 - accuracy: 0.6240 - val_loss: 1.2943 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 346/1800\n",
            "16/16 - 0s - loss: 1.0818 - accuracy: 0.6250 - val_loss: 1.2932 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 347/1800\n",
            "16/16 - 0s - loss: 1.0698 - accuracy: 0.6270 - val_loss: 1.2914 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 348/1800\n",
            "16/16 - 0s - loss: 1.1075 - accuracy: 0.6107 - val_loss: 1.2911 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 349/1800\n",
            "16/16 - 0s - loss: 1.0717 - accuracy: 0.6352 - val_loss: 1.2903 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 350/1800\n",
            "16/16 - 0s - loss: 1.0453 - accuracy: 0.6291 - val_loss: 1.2886 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 351/1800\n",
            "16/16 - 0s - loss: 1.0630 - accuracy: 0.6270 - val_loss: 1.2870 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 352/1800\n",
            "16/16 - 0s - loss: 1.0572 - accuracy: 0.6260 - val_loss: 1.2861 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 353/1800\n",
            "16/16 - 0s - loss: 1.0717 - accuracy: 0.6281 - val_loss: 1.2849 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 354/1800\n",
            "16/16 - 0s - loss: 1.0315 - accuracy: 0.6506 - val_loss: 1.2846 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 355/1800\n",
            "16/16 - 0s - loss: 1.0851 - accuracy: 0.6086 - val_loss: 1.2844 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 356/1800\n",
            "16/16 - 0s - loss: 1.0325 - accuracy: 0.6527 - val_loss: 1.2836 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 357/1800\n",
            "16/16 - 0s - loss: 1.0218 - accuracy: 0.6660 - val_loss: 1.2825 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 358/1800\n",
            "16/16 - 0s - loss: 1.0536 - accuracy: 0.6363 - val_loss: 1.2809 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 359/1800\n",
            "16/16 - 0s - loss: 1.0548 - accuracy: 0.6342 - val_loss: 1.2804 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 360/1800\n",
            "16/16 - 0s - loss: 1.0256 - accuracy: 0.6434 - val_loss: 1.2795 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 361/1800\n",
            "16/16 - 0s - loss: 1.0799 - accuracy: 0.6230 - val_loss: 1.2795 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 362/1800\n",
            "16/16 - 0s - loss: 1.0659 - accuracy: 0.6342 - val_loss: 1.2787 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 363/1800\n",
            "16/16 - 0s - loss: 1.0550 - accuracy: 0.6404 - val_loss: 1.2775 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 364/1800\n",
            "16/16 - 0s - loss: 1.0513 - accuracy: 0.6568 - val_loss: 1.2763 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 365/1800\n",
            "16/16 - 0s - loss: 1.0609 - accuracy: 0.6148 - val_loss: 1.2757 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 366/1800\n",
            "16/16 - 0s - loss: 1.0515 - accuracy: 0.6342 - val_loss: 1.2747 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 367/1800\n",
            "16/16 - 0s - loss: 1.0485 - accuracy: 0.6260 - val_loss: 1.2737 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 368/1800\n",
            "16/16 - 0s - loss: 1.0209 - accuracy: 0.6434 - val_loss: 1.2733 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 369/1800\n",
            "16/16 - 0s - loss: 1.0523 - accuracy: 0.6107 - val_loss: 1.2731 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 370/1800\n",
            "16/16 - 0s - loss: 1.0203 - accuracy: 0.6332 - val_loss: 1.2722 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 371/1800\n",
            "16/16 - 0s - loss: 1.1068 - accuracy: 0.5830 - val_loss: 1.2718 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 372/1800\n",
            "16/16 - 0s - loss: 1.0114 - accuracy: 0.6496 - val_loss: 1.2711 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 373/1800\n",
            "16/16 - 0s - loss: 1.0453 - accuracy: 0.6414 - val_loss: 1.2690 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 374/1800\n",
            "16/16 - 0s - loss: 1.0688 - accuracy: 0.6158 - val_loss: 1.2683 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 375/1800\n",
            "16/16 - 0s - loss: 0.9902 - accuracy: 0.6660 - val_loss: 1.2678 - val_accuracy: 0.6721 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 376/1800\n",
            "16/16 - 0s - loss: 1.0304 - accuracy: 0.6465 - val_loss: 1.2673 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 377/1800\n",
            "16/16 - 0s - loss: 1.0100 - accuracy: 0.6424 - val_loss: 1.2662 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 378/1800\n",
            "16/16 - 0s - loss: 1.0166 - accuracy: 0.6363 - val_loss: 1.2651 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 379/1800\n",
            "16/16 - 0s - loss: 1.0043 - accuracy: 0.6496 - val_loss: 1.2639 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 380/1800\n",
            "16/16 - 0s - loss: 1.0208 - accuracy: 0.6660 - val_loss: 1.2634 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 381/1800\n",
            "16/16 - 0s - loss: 0.9998 - accuracy: 0.6414 - val_loss: 1.2626 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 382/1800\n",
            "16/16 - 0s - loss: 1.0356 - accuracy: 0.6619 - val_loss: 1.2620 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 383/1800\n",
            "16/16 - 0s - loss: 0.9923 - accuracy: 0.6547 - val_loss: 1.2620 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 384/1800\n",
            "16/16 - 0s - loss: 0.9946 - accuracy: 0.6609 - val_loss: 1.2615 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 385/1800\n",
            "16/16 - 0s - loss: 1.0390 - accuracy: 0.6301 - val_loss: 1.2612 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 386/1800\n",
            "16/16 - 0s - loss: 1.0739 - accuracy: 0.6363 - val_loss: 1.2615 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 387/1800\n",
            "16/16 - 0s - loss: 1.0207 - accuracy: 0.6465 - val_loss: 1.2601 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 388/1800\n",
            "16/16 - 0s - loss: 0.9913 - accuracy: 0.6660 - val_loss: 1.2591 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 389/1800\n",
            "16/16 - 0s - loss: 1.0200 - accuracy: 0.6445 - val_loss: 1.2576 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 390/1800\n",
            "16/16 - 0s - loss: 1.0243 - accuracy: 0.6393 - val_loss: 1.2568 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 391/1800\n",
            "16/16 - 0s - loss: 1.0091 - accuracy: 0.6434 - val_loss: 1.2560 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 392/1800\n",
            "16/16 - 0s - loss: 0.9911 - accuracy: 0.6537 - val_loss: 1.2550 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 393/1800\n",
            "16/16 - 0s - loss: 1.0053 - accuracy: 0.6260 - val_loss: 1.2543 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 394/1800\n",
            "16/16 - 0s - loss: 1.0035 - accuracy: 0.6609 - val_loss: 1.2543 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 395/1800\n",
            "16/16 - 0s - loss: 1.0552 - accuracy: 0.6250 - val_loss: 1.2535 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 396/1800\n",
            "16/16 - 0s - loss: 1.0365 - accuracy: 0.6270 - val_loss: 1.2530 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 397/1800\n",
            "16/16 - 0s - loss: 0.9980 - accuracy: 0.6363 - val_loss: 1.2519 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 398/1800\n",
            "16/16 - 0s - loss: 0.9843 - accuracy: 0.6424 - val_loss: 1.2511 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 399/1800\n",
            "16/16 - 0s - loss: 0.9677 - accuracy: 0.6598 - val_loss: 1.2501 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 400/1800\n",
            "16/16 - 0s - loss: 0.9784 - accuracy: 0.6475 - val_loss: 1.2496 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 401/1800\n",
            "16/16 - 0s - loss: 0.9659 - accuracy: 0.6527 - val_loss: 1.2495 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 402/1800\n",
            "16/16 - 0s - loss: 0.9946 - accuracy: 0.6414 - val_loss: 1.2500 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 403/1800\n",
            "16/16 - 0s - loss: 0.9610 - accuracy: 0.6680 - val_loss: 1.2490 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 404/1800\n",
            "16/16 - 0s - loss: 0.9731 - accuracy: 0.6598 - val_loss: 1.2479 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 405/1800\n",
            "16/16 - 0s - loss: 0.9740 - accuracy: 0.6670 - val_loss: 1.2475 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 406/1800\n",
            "16/16 - 0s - loss: 1.0340 - accuracy: 0.6342 - val_loss: 1.2474 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 407/1800\n",
            "16/16 - 0s - loss: 0.9862 - accuracy: 0.6414 - val_loss: 1.2473 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 408/1800\n",
            "16/16 - 0s - loss: 0.9698 - accuracy: 0.6598 - val_loss: 1.2470 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 409/1800\n",
            "16/16 - 0s - loss: 0.9578 - accuracy: 0.6516 - val_loss: 1.2458 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 410/1800\n",
            "16/16 - 0s - loss: 0.9752 - accuracy: 0.6516 - val_loss: 1.2452 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 411/1800\n",
            "16/16 - 0s - loss: 0.9390 - accuracy: 0.6998 - val_loss: 1.2444 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 412/1800\n",
            "16/16 - 0s - loss: 1.0228 - accuracy: 0.6383 - val_loss: 1.2445 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 413/1800\n",
            "16/16 - 0s - loss: 1.0133 - accuracy: 0.6393 - val_loss: 1.2434 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 414/1800\n",
            "16/16 - 0s - loss: 0.9490 - accuracy: 0.6783 - val_loss: 1.2423 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 415/1800\n",
            "16/16 - 0s - loss: 1.0023 - accuracy: 0.6496 - val_loss: 1.2414 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 416/1800\n",
            "16/16 - 0s - loss: 1.0035 - accuracy: 0.6352 - val_loss: 1.2410 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 417/1800\n",
            "16/16 - 0s - loss: 0.9986 - accuracy: 0.6619 - val_loss: 1.2410 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 418/1800\n",
            "16/16 - 0s - loss: 0.9925 - accuracy: 0.6445 - val_loss: 1.2411 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 419/1800\n",
            "16/16 - 0s - loss: 0.9443 - accuracy: 0.6650 - val_loss: 1.2408 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 420/1800\n",
            "16/16 - 0s - loss: 0.9606 - accuracy: 0.6557 - val_loss: 1.2394 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 421/1800\n",
            "16/16 - 0s - loss: 0.9600 - accuracy: 0.6721 - val_loss: 1.2391 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 422/1800\n",
            "16/16 - 0s - loss: 0.9577 - accuracy: 0.6475 - val_loss: 1.2386 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 423/1800\n",
            "16/16 - 0s - loss: 0.9435 - accuracy: 0.6588 - val_loss: 1.2380 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 424/1800\n",
            "16/16 - 0s - loss: 0.9481 - accuracy: 0.6465 - val_loss: 1.2382 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 425/1800\n",
            "16/16 - 0s - loss: 0.8828 - accuracy: 0.6936 - val_loss: 1.2376 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 426/1800\n",
            "16/16 - 0s - loss: 0.9296 - accuracy: 0.6885 - val_loss: 1.2370 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 427/1800\n",
            "16/16 - 0s - loss: 0.9750 - accuracy: 0.6424 - val_loss: 1.2368 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 428/1800\n",
            "16/16 - 0s - loss: 0.9603 - accuracy: 0.6660 - val_loss: 1.2369 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 429/1800\n",
            "16/16 - 0s - loss: 0.9955 - accuracy: 0.6301 - val_loss: 1.2369 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 430/1800\n",
            "16/16 - 0s - loss: 0.9405 - accuracy: 0.6721 - val_loss: 1.2371 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 431/1800\n",
            "16/16 - 0s - loss: 0.9345 - accuracy: 0.6701 - val_loss: 1.2367 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 432/1800\n",
            "16/16 - 0s - loss: 0.9812 - accuracy: 0.6557 - val_loss: 1.2365 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 433/1800\n",
            "16/16 - 0s - loss: 0.9408 - accuracy: 0.6568 - val_loss: 1.2365 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 434/1800\n",
            "16/16 - 0s - loss: 0.9740 - accuracy: 0.6383 - val_loss: 1.2358 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 435/1800\n",
            "16/16 - 0s - loss: 0.9521 - accuracy: 0.6588 - val_loss: 1.2352 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 61ms/epoch - 4ms/step\n",
            "Epoch 436/1800\n",
            "16/16 - 0s - loss: 0.9695 - accuracy: 0.6496 - val_loss: 1.2349 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 437/1800\n",
            "16/16 - 0s - loss: 0.8820 - accuracy: 0.6895 - val_loss: 1.2341 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 438/1800\n",
            "16/16 - 0s - loss: 0.9711 - accuracy: 0.6629 - val_loss: 1.2325 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 439/1800\n",
            "16/16 - 0s - loss: 0.9543 - accuracy: 0.6578 - val_loss: 1.2324 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 440/1800\n",
            "16/16 - 0s - loss: 0.9341 - accuracy: 0.6598 - val_loss: 1.2322 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 441/1800\n",
            "16/16 - 0s - loss: 0.9236 - accuracy: 0.6721 - val_loss: 1.2320 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 442/1800\n",
            "16/16 - 0s - loss: 0.9433 - accuracy: 0.6619 - val_loss: 1.2315 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 443/1800\n",
            "16/16 - 0s - loss: 0.9794 - accuracy: 0.6301 - val_loss: 1.2309 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 444/1800\n",
            "16/16 - 0s - loss: 0.9341 - accuracy: 0.6527 - val_loss: 1.2307 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 445/1800\n",
            "16/16 - 0s - loss: 0.9318 - accuracy: 0.6783 - val_loss: 1.2307 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 446/1800\n",
            "16/16 - 0s - loss: 0.9169 - accuracy: 0.6598 - val_loss: 1.2307 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 447/1800\n",
            "16/16 - 0s - loss: 0.9193 - accuracy: 0.6588 - val_loss: 1.2296 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 448/1800\n",
            "16/16 - 0s - loss: 0.9479 - accuracy: 0.6414 - val_loss: 1.2290 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 449/1800\n",
            "16/16 - 0s - loss: 0.9464 - accuracy: 0.6486 - val_loss: 1.2284 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 450/1800\n",
            "16/16 - 0s - loss: 0.9048 - accuracy: 0.6834 - val_loss: 1.2278 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 451/1800\n",
            "16/16 - 0s - loss: 0.9082 - accuracy: 0.6752 - val_loss: 1.2269 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 452/1800\n",
            "16/16 - 0s - loss: 0.9230 - accuracy: 0.6895 - val_loss: 1.2264 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 453/1800\n",
            "16/16 - 0s - loss: 0.9348 - accuracy: 0.6629 - val_loss: 1.2269 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 454/1800\n",
            "16/16 - 0s - loss: 0.9079 - accuracy: 0.6865 - val_loss: 1.2274 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 455/1800\n",
            "16/16 - 0s - loss: 0.8775 - accuracy: 0.6906 - val_loss: 1.2273 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 456/1800\n",
            "16/16 - 0s - loss: 0.9179 - accuracy: 0.6660 - val_loss: 1.2268 - val_accuracy: 0.6557 - lr: 1.0000e-04 - 56ms/epoch - 3ms/step\n",
            "Epoch 457/1800\n",
            "16/16 - 0s - loss: 0.9066 - accuracy: 0.6875 - val_loss: 1.2259 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 458/1800\n",
            "16/16 - 0s - loss: 0.9245 - accuracy: 0.6578 - val_loss: 1.2257 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 459/1800\n",
            "16/16 - 0s - loss: 0.8802 - accuracy: 0.6824 - val_loss: 1.2257 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 55ms/epoch - 3ms/step\n",
            "Epoch 460/1800\n",
            "16/16 - 0s - loss: 0.9212 - accuracy: 0.6711 - val_loss: 1.2260 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 461/1800\n",
            "16/16 - 0s - loss: 0.9185 - accuracy: 0.6742 - val_loss: 1.2258 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 462/1800\n",
            "16/16 - 0s - loss: 0.9415 - accuracy: 0.6609 - val_loss: 1.2257 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 463/1800\n",
            "16/16 - 0s - loss: 0.8992 - accuracy: 0.6660 - val_loss: 1.2260 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 464/1800\n",
            "16/16 - 0s - loss: 0.9058 - accuracy: 0.6773 - val_loss: 1.2262 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 465/1800\n",
            "16/16 - 0s - loss: 0.8726 - accuracy: 0.6762 - val_loss: 1.2256 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 466/1800\n",
            "16/16 - 0s - loss: 0.8805 - accuracy: 0.6936 - val_loss: 1.2254 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 467/1800\n",
            "16/16 - 0s - loss: 0.9077 - accuracy: 0.6691 - val_loss: 1.2250 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 468/1800\n",
            "16/16 - 0s - loss: 0.9144 - accuracy: 0.6680 - val_loss: 1.2250 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 469/1800\n",
            "16/16 - 0s - loss: 0.9242 - accuracy: 0.6762 - val_loss: 1.2254 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 470/1800\n",
            "16/16 - 0s - loss: 0.9203 - accuracy: 0.6803 - val_loss: 1.2253 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 471/1800\n",
            "16/16 - 0s - loss: 0.8805 - accuracy: 0.6936 - val_loss: 1.2248 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 472/1800\n",
            "16/16 - 0s - loss: 0.8931 - accuracy: 0.6752 - val_loss: 1.2244 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 473/1800\n",
            "16/16 - 0s - loss: 0.9170 - accuracy: 0.6711 - val_loss: 1.2244 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 474/1800\n",
            "16/16 - 0s - loss: 0.8967 - accuracy: 0.6680 - val_loss: 1.2242 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 475/1800\n",
            "16/16 - 0s - loss: 0.8790 - accuracy: 0.6814 - val_loss: 1.2244 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 476/1800\n",
            "16/16 - 0s - loss: 0.8775 - accuracy: 0.6732 - val_loss: 1.2245 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 477/1800\n",
            "16/16 - 0s - loss: 0.8980 - accuracy: 0.6752 - val_loss: 1.2234 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 478/1800\n",
            "16/16 - 0s - loss: 0.8834 - accuracy: 0.6844 - val_loss: 1.2231 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 479/1800\n",
            "16/16 - 0s - loss: 0.8874 - accuracy: 0.6701 - val_loss: 1.2227 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 480/1800\n",
            "16/16 - 0s - loss: 0.9145 - accuracy: 0.6639 - val_loss: 1.2228 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 481/1800\n",
            "16/16 - 0s - loss: 0.9337 - accuracy: 0.6568 - val_loss: 1.2217 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 482/1800\n",
            "16/16 - 0s - loss: 0.8855 - accuracy: 0.6844 - val_loss: 1.2212 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 483/1800\n",
            "16/16 - 0s - loss: 0.8743 - accuracy: 0.6803 - val_loss: 1.2203 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 484/1800\n",
            "16/16 - 0s - loss: 0.8634 - accuracy: 0.6875 - val_loss: 1.2195 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 485/1800\n",
            "16/16 - 0s - loss: 0.8960 - accuracy: 0.6711 - val_loss: 1.2194 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 486/1800\n",
            "16/16 - 0s - loss: 0.8843 - accuracy: 0.6742 - val_loss: 1.2197 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 487/1800\n",
            "16/16 - 0s - loss: 0.9040 - accuracy: 0.6793 - val_loss: 1.2195 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 488/1800\n",
            "16/16 - 0s - loss: 0.8297 - accuracy: 0.6977 - val_loss: 1.2197 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 489/1800\n",
            "16/16 - 0s - loss: 0.9131 - accuracy: 0.6721 - val_loss: 1.2193 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 490/1800\n",
            "16/16 - 0s - loss: 0.8813 - accuracy: 0.6875 - val_loss: 1.2186 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 491/1800\n",
            "16/16 - 0s - loss: 0.8698 - accuracy: 0.6711 - val_loss: 1.2183 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 492/1800\n",
            "16/16 - 0s - loss: 0.9407 - accuracy: 0.6650 - val_loss: 1.2189 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 493/1800\n",
            "16/16 - 0s - loss: 0.8385 - accuracy: 0.6998 - val_loss: 1.2192 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 494/1800\n",
            "16/16 - 0s - loss: 0.8610 - accuracy: 0.6885 - val_loss: 1.2189 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 495/1800\n",
            "16/16 - 0s - loss: 0.8750 - accuracy: 0.6814 - val_loss: 1.2185 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 496/1800\n",
            "16/16 - 0s - loss: 0.8851 - accuracy: 0.6701 - val_loss: 1.2182 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 497/1800\n",
            "16/16 - 0s - loss: 0.8674 - accuracy: 0.6803 - val_loss: 1.2178 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 498/1800\n",
            "16/16 - 0s - loss: 0.8698 - accuracy: 0.6732 - val_loss: 1.2173 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 499/1800\n",
            "16/16 - 0s - loss: 0.8601 - accuracy: 0.6844 - val_loss: 1.2160 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 500/1800\n",
            "16/16 - 0s - loss: 0.8434 - accuracy: 0.6967 - val_loss: 1.2158 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 501/1800\n",
            "16/16 - 0s - loss: 0.8397 - accuracy: 0.6895 - val_loss: 1.2162 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 502/1800\n",
            "16/16 - 0s - loss: 0.9157 - accuracy: 0.6773 - val_loss: 1.2163 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 503/1800\n",
            "16/16 - 0s - loss: 0.8848 - accuracy: 0.6773 - val_loss: 1.2167 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 504/1800\n",
            "16/16 - 0s - loss: 0.8738 - accuracy: 0.6895 - val_loss: 1.2168 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 505/1800\n",
            "16/16 - 0s - loss: 0.8771 - accuracy: 0.6916 - val_loss: 1.2166 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 506/1800\n",
            "16/16 - 0s - loss: 0.8619 - accuracy: 0.6875 - val_loss: 1.2158 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 507/1800\n",
            "16/16 - 0s - loss: 0.8876 - accuracy: 0.6824 - val_loss: 1.2148 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 60ms/epoch - 4ms/step\n",
            "Epoch 508/1800\n",
            "16/16 - 0s - loss: 0.8873 - accuracy: 0.6650 - val_loss: 1.2146 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 509/1800\n",
            "16/16 - 0s - loss: 0.8922 - accuracy: 0.6680 - val_loss: 1.2148 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 510/1800\n",
            "16/16 - 0s - loss: 0.8762 - accuracy: 0.6619 - val_loss: 1.2147 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 511/1800\n",
            "16/16 - 0s - loss: 0.8624 - accuracy: 0.6834 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 512/1800\n",
            "16/16 - 0s - loss: 0.8629 - accuracy: 0.6721 - val_loss: 1.2143 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 56ms/epoch - 4ms/step\n",
            "Epoch 513/1800\n",
            "16/16 - 0s - loss: 0.8924 - accuracy: 0.6660 - val_loss: 1.2145 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 514/1800\n",
            "16/16 - 0s - loss: 0.8615 - accuracy: 0.6701 - val_loss: 1.2148 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 57ms/epoch - 4ms/step\n",
            "Epoch 515/1800\n",
            "16/16 - 0s - loss: 0.8170 - accuracy: 0.7090 - val_loss: 1.2153 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 516/1800\n",
            "16/16 - 0s - loss: 0.8612 - accuracy: 0.6885 - val_loss: 1.2150 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 59ms/epoch - 4ms/step\n",
            "Epoch 517/1800\n",
            "16/16 - 0s - loss: 0.8988 - accuracy: 0.6619 - val_loss: 1.2144 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 518/1800\n",
            "16/16 - 0s - loss: 0.7985 - accuracy: 0.6977 - val_loss: 1.2143 - val_accuracy: 0.6639 - lr: 1.0000e-04 - 58ms/epoch - 4ms/step\n",
            "Epoch 519/1800\n",
            "16/16 - 0s - loss: 0.8542 - accuracy: 0.6783 - val_loss: 1.2143 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 520/1800\n",
            "16/16 - 0s - loss: 0.8527 - accuracy: 0.6855 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 521/1800\n",
            "16/16 - 0s - loss: 0.8593 - accuracy: 0.6834 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 522/1800\n",
            "16/16 - 0s - loss: 0.8715 - accuracy: 0.6742 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 61ms/epoch - 4ms/step\n",
            "Epoch 523/1800\n",
            "16/16 - 0s - loss: 0.9025 - accuracy: 0.6680 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 61ms/epoch - 4ms/step\n",
            "Epoch 524/1800\n",
            "16/16 - 0s - loss: 0.8892 - accuracy: 0.6773 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 61ms/epoch - 4ms/step\n",
            "Epoch 525/1800\n",
            "16/16 - 0s - loss: 0.8536 - accuracy: 0.6957 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 526/1800\n",
            "16/16 - 0s - loss: 0.8205 - accuracy: 0.7008 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 527/1800\n",
            "16/16 - 0s - loss: 0.8168 - accuracy: 0.7018 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 528/1800\n",
            "16/16 - 0s - loss: 0.8019 - accuracy: 0.7049 - val_loss: 1.2142 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 58ms/epoch - 4ms/step\n",
            "Epoch 529/1800\n",
            "16/16 - 0s - loss: 0.8640 - accuracy: 0.6803 - val_loss: 1.2141 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 63ms/epoch - 4ms/step\n",
            "Epoch 530/1800\n",
            "16/16 - 0s - loss: 0.8181 - accuracy: 0.7008 - val_loss: 1.2140 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 62ms/epoch - 4ms/step\n",
            "Epoch 531/1800\n",
            "16/16 - 0s - loss: 0.8715 - accuracy: 0.6680 - val_loss: 1.2140 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 532/1800\n",
            "16/16 - 0s - loss: 0.8682 - accuracy: 0.6783 - val_loss: 1.2139 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 533/1800\n",
            "16/16 - 0s - loss: 0.8623 - accuracy: 0.6721 - val_loss: 1.2139 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 534/1800\n",
            "16/16 - 0s - loss: 0.8501 - accuracy: 0.6742 - val_loss: 1.2139 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 58ms/epoch - 4ms/step\n",
            "Epoch 535/1800\n",
            "16/16 - 0s - loss: 0.8509 - accuracy: 0.6721 - val_loss: 1.2139 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 536/1800\n",
            "16/16 - 0s - loss: 0.8212 - accuracy: 0.6967 - val_loss: 1.2138 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 61ms/epoch - 4ms/step\n",
            "Epoch 537/1800\n",
            "16/16 - 0s - loss: 0.8386 - accuracy: 0.7070 - val_loss: 1.2137 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 538/1800\n",
            "16/16 - 0s - loss: 0.8081 - accuracy: 0.7059 - val_loss: 1.2137 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 539/1800\n",
            "16/16 - 0s - loss: 0.8573 - accuracy: 0.6865 - val_loss: 1.2137 - val_accuracy: 0.6639 - lr: 1.0000e-05 - 61ms/epoch - 4ms/step\n",
            "Epoch 540/1800\n",
            "16/16 - 0s - loss: 0.8535 - accuracy: 0.6824 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 541/1800\n",
            "16/16 - 0s - loss: 0.8579 - accuracy: 0.6721 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 542/1800\n",
            "16/16 - 0s - loss: 0.8361 - accuracy: 0.6660 - val_loss: 1.2138 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 543/1800\n",
            "16/16 - 0s - loss: 0.8500 - accuracy: 0.6906 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 544/1800\n",
            "16/16 - 0s - loss: 0.8417 - accuracy: 0.6773 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 545/1800\n",
            "16/16 - 0s - loss: 0.8267 - accuracy: 0.7100 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 546/1800\n",
            "16/16 - 0s - loss: 0.8704 - accuracy: 0.6680 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 547/1800\n",
            "16/16 - 0s - loss: 0.8399 - accuracy: 0.6998 - val_loss: 1.2138 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 548/1800\n",
            "16/16 - 0s - loss: 0.8756 - accuracy: 0.6721 - val_loss: 1.2138 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 549/1800\n",
            "16/16 - 0s - loss: 0.8259 - accuracy: 0.6988 - val_loss: 1.2139 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 58ms/epoch - 4ms/step\n",
            "Epoch 550/1800\n",
            "16/16 - 0s - loss: 0.7678 - accuracy: 0.7336 - val_loss: 1.2138 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 551/1800\n",
            "16/16 - 0s - loss: 0.8185 - accuracy: 0.7008 - val_loss: 1.2138 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 59ms/epoch - 4ms/step\n",
            "Epoch 552/1800\n",
            "16/16 - 0s - loss: 0.8274 - accuracy: 0.7080 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-05 - 60ms/epoch - 4ms/step\n",
            "Epoch 553/1800\n",
            "16/16 - 0s - loss: 0.8617 - accuracy: 0.6732 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 61ms/epoch - 4ms/step\n",
            "Epoch 554/1800\n",
            "16/16 - 0s - loss: 0.8321 - accuracy: 0.6803 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 57ms/epoch - 4ms/step\n",
            "Epoch 555/1800\n",
            "16/16 - 0s - loss: 0.8447 - accuracy: 0.6926 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 65ms/epoch - 4ms/step\n",
            "Epoch 556/1800\n",
            "16/16 - 0s - loss: 0.8358 - accuracy: 0.7039 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 59ms/epoch - 4ms/step\n",
            "Epoch 557/1800\n",
            "16/16 - 0s - loss: 0.8329 - accuracy: 0.6988 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 58ms/epoch - 4ms/step\n",
            "Epoch 558/1800\n",
            "16/16 - 0s - loss: 0.8026 - accuracy: 0.7193 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 59ms/epoch - 4ms/step\n",
            "Epoch 559/1800\n",
            "16/16 - 0s - loss: 0.8318 - accuracy: 0.7049 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-06 - 60ms/epoch - 4ms/step\n",
            "Epoch 560/1800\n",
            "16/16 - 0s - loss: 0.8497 - accuracy: 0.6885 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 59ms/epoch - 4ms/step\n",
            "Epoch 561/1800\n",
            "16/16 - 0s - loss: 0.8429 - accuracy: 0.6814 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 62ms/epoch - 4ms/step\n",
            "Epoch 562/1800\n",
            "16/16 - 0s - loss: 0.8378 - accuracy: 0.6926 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 59ms/epoch - 4ms/step\n",
            "Epoch 563/1800\n",
            "16/16 - 0s - loss: 0.8750 - accuracy: 0.6691 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 61ms/epoch - 4ms/step\n",
            "Epoch 564/1800\n",
            "16/16 - 0s - loss: 0.8749 - accuracy: 0.6650 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 61ms/epoch - 4ms/step\n",
            "Epoch 565/1800\n",
            "16/16 - 0s - loss: 0.8667 - accuracy: 0.6721 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 60ms/epoch - 4ms/step\n",
            "Epoch 566/1800\n",
            "16/16 - 0s - loss: 0.8442 - accuracy: 0.6875 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-07 - 59ms/epoch - 4ms/step\n",
            "Epoch 567/1800\n",
            "16/16 - 0s - loss: 0.8212 - accuracy: 0.7141 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-08 - 59ms/epoch - 4ms/step\n",
            "Epoch 568/1800\n",
            "16/16 - 0s - loss: 0.8385 - accuracy: 0.6885 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-08 - 57ms/epoch - 4ms/step\n",
            "Epoch 569/1800\n",
            "16/16 - 0s - loss: 0.8457 - accuracy: 0.6783 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-08 - 60ms/epoch - 4ms/step\n",
            "Epoch 570/1800\n",
            "16/16 - 0s - loss: 0.8601 - accuracy: 0.6670 - val_loss: 1.2137 - val_accuracy: 0.6721 - lr: 1.0000e-08 - 59ms/epoch - 4ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')  \n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                  factor=0.1, patience=7, verbose=0, min_delta=1e-119, mode='min')\n",
        "history = model1.fit(train_x, y_train, validation_data=(valid_x, y_valid), class_weight=class_weights_dict45,\n",
        "            shuffle=True, verbose=2, epochs=1800, batch_size=64,\n",
        "            callbacks=[earlyStopping, checkpoint_mlp, reduce_lr_loss])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "from keras.models import load_model\n",
        "best_model = load_model(filepath_mlp)"
      ],
      "metadata": {
        "id": "iGHXy6V2gONJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DsUtgBRqOj8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c229b7-8f94-49bc-c098-540f65e2bf06"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.67"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "valid_accuracy = round(best_model.evaluate(valid_x, y_valid, verbose=0, batch_size=64)[1], 2)\n",
        "valid_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ScVSLvv4fDv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47fe6e30-3375-4981-ca4e-aa0cd97e1241"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         3\n",
            "           1       1.00      0.60      0.75         5\n",
            "           2       0.43      0.43      0.43         7\n",
            "           3       0.62      0.83      0.71         6\n",
            "           4       0.50      0.62      0.56         8\n",
            "           5       1.00      0.40      0.57         5\n",
            "           6       0.75      0.60      0.67        10\n",
            "           7       0.43      0.50      0.46         6\n",
            "           8       1.00      0.75      0.86         4\n",
            "           9       1.00      0.75      0.86         4\n",
            "          10       0.50      0.33      0.40         3\n",
            "          11       0.40      0.50      0.44         4\n",
            "          12       0.62      0.71      0.67         7\n",
            "          13       0.67      1.00      0.80         4\n",
            "          14       1.00      0.90      0.95        10\n",
            "          15       0.67      0.60      0.63        10\n",
            "          16       0.80      1.00      0.89         4\n",
            "          17       0.75      0.43      0.55         7\n",
            "          18       0.60      0.75      0.67         8\n",
            "          19       0.60      0.86      0.71         7\n",
            "\n",
            "    accuracy                           0.67       122\n",
            "   macro avg       0.72      0.68      0.68       122\n",
            "weighted avg       0.71      0.67      0.67       122\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         4\n",
            "           1       1.00      0.75      0.86         4\n",
            "           2       0.80      0.57      0.67         7\n",
            "           3       0.60      0.50      0.55         6\n",
            "           4       0.53      1.00      0.70         8\n",
            "           5       0.80      0.80      0.80         5\n",
            "           6       0.88      0.70      0.78        10\n",
            "           7       0.62      0.83      0.71         6\n",
            "           8       1.00      1.00      1.00         4\n",
            "           9       1.00      1.00      1.00         5\n",
            "          10       0.50      0.50      0.50         4\n",
            "          11       0.17      0.25      0.20         4\n",
            "          12       0.57      0.67      0.62         6\n",
            "          13       0.50      0.25      0.33         4\n",
            "          14       1.00      0.90      0.95        10\n",
            "          15       0.67      0.60      0.63        10\n",
            "          16       1.00      0.75      0.86         4\n",
            "          17       0.57      0.57      0.57         7\n",
            "          18       0.60      0.75      0.67         8\n",
            "          19       0.75      0.43      0.55         7\n",
            "\n",
            "    accuracy                           0.70       123\n",
            "   macro avg       0.73      0.69      0.70       123\n",
            "weighted avg       0.73      0.70      0.70       123\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model \n",
        "from sklearn.metrics import classification_report\n",
        "assert list(y_test)[0:5] == [14, 12, 6, 13, 14]\n",
        "print(classification_report(y_valid, np.array(best_model.predict(valid_x).argmax(-1)),))\n",
        "print(classification_report(y_test, np.array(best_model.predict(test_x).argmax(-1)),))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QnTRonUbnyqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "f1194d57-bd16-437e-c2ef-bc4eb43f236e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "# https://future-chem.com/rdkit-google-colab/#toc5\n",
        "# https://www.rdkit.org/docs/index.html"
      ],
      "metadata": {
        "id": "dmteC1TiiXFE"
      },
      "execution_count": 35,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "MLP_top_20_MOA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}