{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75-UZEGR1A0b"
      },
      "outputs": [],
      "source": [
        "# install rdkit  \n",
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!conda install -q -y -c rdkit rdkit python=3.7\n",
        "import sys\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import pprint     \n",
        "pprint.pprint(sys.path)\n",
        "!python -c \"import site; print (site.getsitepackages())\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('top_50_MOAs.txt', sep = '\\t')\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "O9GYJo2v9Zu9",
        "outputId": "f26e4c9e-1830-4fee-ffaf-a90cec567be3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "1958                   Cn1c2ncn(CC(O)=O)c2c(=O)n(C)c1=O   \n",
              "1959  CCNC(=O)[C@H]1O[C@H]([C@H](O)[C@@H]1O)n1cnc2c(...   \n",
              "1960  CCNC(=O)[C@H]1O[C@H]([C@@H](O)[C@@H]1O)n1cnc2c...   \n",
              "1961              Cc1sc(N)c(C(=O)c2cccc(c2)C(F)(F)F)c1C   \n",
              "1962  C[C@@]1(O)[C@H](O)[C@@H](CO)O[C@H]1n1cnc2c(NC3...   \n",
              "\n",
              "                                 MOA  \n",
              "0     adrenergic receptor antagonist  \n",
              "1     adrenergic receptor antagonist  \n",
              "2     adrenergic receptor antagonist  \n",
              "3     adrenergic receptor antagonist  \n",
              "4     adrenergic receptor antagonist  \n",
              "...                              ...  \n",
              "1958      adenosine receptor agonist  \n",
              "1959      adenosine receptor agonist  \n",
              "1960      adenosine receptor agonist  \n",
              "1961      adenosine receptor agonist  \n",
              "1962      adenosine receptor agonist  \n",
              "\n",
              "[1963 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-46c9407b-5c13-48a6-9b10-bbac992cde7d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>Cn1c2ncn(CC(O)=O)c2c(=O)n(C)c1=O</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>CCNC(=O)[C@H]1O[C@H]([C@H](O)[C@@H]1O)n1cnc2c(...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>CCNC(=O)[C@H]1O[C@H]([C@@H](O)[C@@H]1O)n1cnc2c...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>Cc1sc(N)c(C(=O)c2cccc(c2)C(F)(F)F)c1C</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>C[C@@]1(O)[C@H](O)[C@@H](CO)O[C@H]1n1cnc2c(NC3...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1963 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-46c9407b-5c13-48a6-9b10-bbac992cde7d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-46c9407b-5c13-48a6-9b10-bbac992cde7d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-46c9407b-5c13-48a6-9b10-bbac992cde7d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the duplicates \n",
        "for i in df.SMILES.tolist():\n",
        "  if df.SMILES.tolist().count(i) != 1:\n",
        "    print(i)"
      ],
      "metadata": {
        "id": "6S0Cz1ly_sZk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOA_class_dictionary = {'ATPase inhibitor': 45,\n",
        " 'Aurora kinase inhibitor': 7,\n",
        " 'CC chemokine receptor antagonist': 13,\n",
        " 'CDK inhibitor': 37,\n",
        " 'DNA synthesis inhibitor': 29,\n",
        " 'EGFR inhibitor': 41,\n",
        " 'HCV inhibitor': 25,\n",
        " 'HDAC inhibitor': 26,\n",
        " 'HSP inhibitor': 23,\n",
        " 'JAK inhibitor': 32,\n",
        " 'MEK inhibitor': 5,\n",
        " 'PARP inhibitor': 16,\n",
        " 'PI3K inhibitor': 49,\n",
        " 'PPAR receptor agonist': 9,\n",
        " 'acetylcholine receptor agonist': 36,\n",
        " 'acetylcholine receptor antagonist': 1,\n",
        " 'acetylcholinesterase inhibitor': 46,\n",
        " 'adenosine receptor agonist': 8,\n",
        " 'adenosine receptor antagonist': 44,\n",
        " 'adrenergic receptor agonist': 22,\n",
        " 'adrenergic receptor antagonist': 10,\n",
        " 'angiotensin converting enzyme inhibitor': 6,\n",
        " 'antioxidant': 47,\n",
        " 'bacterial 30S ribosomal subunit inhibitor': 14,\n",
        " 'bacterial DNA gyrase inhibitor': 18,\n",
        " 'bacterial cell wall synthesis inhibitor': 43,\n",
        " 'benzodiazepine receptor agonist': 33,\n",
        " 'bromodomain inhibitor': 2,\n",
        " 'calcium channel blocker': 42,\n",
        " 'cyclooxygenase inhibitor': 12,\n",
        " 'cytochrome P450 inhibitor': 30,\n",
        " 'dopamine receptor agonist': 48,\n",
        " 'dopamine receptor antagonist': 27,\n",
        " 'estrogen receptor agonist': 35,\n",
        " 'glucocorticoid receptor agonist': 4,\n",
        " 'glutamate receptor agonist': 19,\n",
        " 'glutamate receptor antagonist': 20,\n",
        " 'histamine receptor antagonist': 24,\n",
        " 'histone lysine methyltransferase inhibitor': 11,\n",
        " 'local anesthetic': 34,\n",
        " 'monoamine oxidase inhibitor': 17,\n",
        " 'opioid receptor agonist': 31,\n",
        " 'phosphodiesterase inhibitor': 40,\n",
        " 'potassium channel blocker': 15,\n",
        " 'protein synthesis inhibitor': 28,\n",
        " 'serotonin receptor agonist': 38,\n",
        " 'serotonin receptor antagonist': 3,\n",
        " 'sodium channel blocker': 39,\n",
        " 'topoisomerase inhibitor': 21,\n",
        " 'tubulin polymerization inhibitor': 0}  "
      ],
      "metadata": {
        "id": "17c5-JuGBwb0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sorted_classes = list(MOA_class_dictionary.values())\n",
        "sorted_classes.sort() \n",
        "assert sorted_classes == [i for i in range(50)]"
      ],
      "metadata": {
        "id": "NkFqARR_B72C"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# add classes column \n",
        "df['classes'] = None\n",
        "for i in range(df.shape[0]):\n",
        "  df.iloc[i,2] = MOA_class_dictionary[df.iloc[i,1]]\n",
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lF5D5wb6CRCn",
        "outputId": "b111482b-8e73-4c32-8905-20098609823b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                 SMILES  \\\n",
              "0                       Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1                  OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2           O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "3            O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1   \n",
              "4     O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...   \n",
              "...                                                 ...   \n",
              "1958                   Cn1c2ncn(CC(O)=O)c2c(=O)n(C)c1=O   \n",
              "1959  CCNC(=O)[C@H]1O[C@H]([C@H](O)[C@@H]1O)n1cnc2c(...   \n",
              "1960  CCNC(=O)[C@H]1O[C@H]([C@@H](O)[C@@H]1O)n1cnc2c...   \n",
              "1961              Cc1sc(N)c(C(=O)c2cccc(c2)C(F)(F)F)c1C   \n",
              "1962  C[C@@]1(O)[C@H](O)[C@@H](CO)O[C@H]1n1cnc2c(NC3...   \n",
              "\n",
              "                                 MOA classes  \n",
              "0     adrenergic receptor antagonist      10  \n",
              "1     adrenergic receptor antagonist      10  \n",
              "2     adrenergic receptor antagonist      10  \n",
              "3     adrenergic receptor antagonist      10  \n",
              "4     adrenergic receptor antagonist      10  \n",
              "...                              ...     ...  \n",
              "1958      adenosine receptor agonist       8  \n",
              "1959      adenosine receptor agonist       8  \n",
              "1960      adenosine receptor agonist       8  \n",
              "1961      adenosine receptor agonist       8  \n",
              "1962      adenosine receptor agonist       8  \n",
              "\n",
              "[1963 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-19e8c635-e191-419e-921a-f233d3727125\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>O=C(NC1CCN(CCc2c[nH]c3ccccc23)CC1)c1ccccc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>O[C@H](CNC[C@@H](O)[C@@H]1CCc2cc(F)ccc2O1)[C@H...</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1958</th>\n",
              "      <td>Cn1c2ncn(CC(O)=O)c2c(=O)n(C)c1=O</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1959</th>\n",
              "      <td>CCNC(=O)[C@H]1O[C@H]([C@H](O)[C@@H]1O)n1cnc2c(...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>CCNC(=O)[C@H]1O[C@H]([C@@H](O)[C@@H]1O)n1cnc2c...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>Cc1sc(N)c(C(=O)c2cccc(c2)C(F)(F)F)c1C</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>C[C@@]1(O)[C@H](O)[C@@H](CO)O[C@H]1n1cnc2c(NC3...</td>\n",
              "      <td>adenosine receptor agonist</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1963 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-19e8c635-e191-419e-921a-f233d3727125')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-19e8c635-e191-419e-921a-f233d3727125 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-19e8c635-e191-419e-921a-f233d3727125');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that changes smiles string to fingerprints \n",
        "import rdkit\n",
        "import numpy as np\n",
        "from rdkit import *\n",
        "from rdkit import Chem, DataStructs\n",
        "from rdkit.Chem import AllChem\n",
        "def smiles_to_array_to_string(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays  = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = list((np.squeeze(x_array)).astype(int))\n",
        "  string = ''\n",
        "  for i in x_array:\n",
        "    string += str(i) \n",
        "  return string"
      ],
      "metadata": {
        "id": "RfbsXXcT_sb7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the existence of Isomers\n",
        "assert len(set([smiles_to_array_to_string(i) for i in df.SMILES.tolist()])) == df.shape[0]"
      ],
      "metadata": {
        "id": "1u3oVoqMFh94"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "CFagctK7GiTn",
        "outputId": "7186bf69-09cb-422c-837d-f51657aadd1d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        SMILES  \\\n",
              "0              Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1   \n",
              "1         OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N   \n",
              "2  O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12   \n",
              "\n",
              "                              MOA classes  \n",
              "0  adrenergic receptor antagonist      10  \n",
              "1  adrenergic receptor antagonist      10  \n",
              "2  adrenergic receptor antagonist      10  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-580dbe53-e72c-4463-90fb-ba2f53951cd2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>SMILES</th>\n",
              "      <th>MOA</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Oc1ccc(CCNCC2CCc3ccccc3C2=O)cc1</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OC(CNCCNC(=O)Nc1ccccc1)COc1ccccc1C#N</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>O=C1Nc2ccccc2C2=NC(CN3CCN(CC3)c3ccccc3)CN12</td>\n",
              "      <td>adrenergic receptor antagonist</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-580dbe53-e72c-4463-90fb-ba2f53951cd2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-580dbe53-e72c-4463-90fb-ba2f53951cd2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-580dbe53-e72c-4463-90fb-ba2f53951cd2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xowg0CstLlC-"
      },
      "outputs": [],
      "source": [
        "# Split out the test set  \n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train_valid, x_test, y_train_valid, y_test = train_test_split(df.SMILES, df.classes, test_size =10/100,\n",
        " stratify = df.classes, shuffle = True, random_state = 1000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BLlcRhSeU6xW"
      },
      "outputs": [],
      "source": [
        "# kfold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "skf = StratifiedKFold(n_splits = 9)\n",
        "skf.get_n_splits(np.array(list(x_train_valid)), np.array(list(y_train_valid)))\n",
        "train_index_list = []\n",
        "valid_index_list = []\n",
        "for train_index, valid_index in skf.split(np.array(list(x_train_valid)), np.array(list(y_train_valid))):\n",
        "  train_index_list.append(train_index)\n",
        "  valid_index_list.append(valid_index)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a_list = []\n",
        "for i in range(9):\n",
        "  a_list += list(np.array(list(x_train_valid))[valid_index_list[i]])"
      ],
      "metadata": {
        "id": "JQT77vDlTeNy"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DEqt9fUnDqBe"
      },
      "outputs": [],
      "source": [
        "number_of_kfold = 8 # change the number from 0-8 to get 9 shuffles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "aOFIJo5MEMT0"
      },
      "outputs": [],
      "source": [
        "  x_train = list(np.array(list(x_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  x_valid = list(np.array(list(x_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  y_train = list(np.array(list(y_train_valid))[train_index_list[ number_of_kfold ]])\n",
        "  y_valid = list(np.array(list(y_train_valid))[valid_index_list[ number_of_kfold ]])\n",
        "  x_test = list(x_test)\n",
        "  y_test = list(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L0OPr-gtR8sj"
      },
      "outputs": [],
      "source": [
        "# turn to cannoical  smiles\n",
        "x_train = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_train]\n",
        "x_valid = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_valid]\n",
        "x_test = [Chem.MolToSmiles(Chem.MolFromSmiles(smi),True) for smi in x_test]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ZB4WWi8wKB59"
      },
      "outputs": [],
      "source": [
        "def smiles_to_array(smiles):\n",
        "  molecules = Chem.MolFromSmiles(smiles) \n",
        "  fingerprints = AllChem.GetMorganFingerprintAsBitVect(molecules, 2)\n",
        "  x_array = []\n",
        "  arrays = np.zeros(0,)\n",
        "  DataStructs.ConvertToNumpyArray(fingerprints, arrays)\n",
        "  x_array.append(arrays)\n",
        "  x_array = np.asarray(x_array)\n",
        "  x_array = ((np.squeeze(x_array)).astype(int)) \n",
        "  return x_array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "a6Fy6iGdLSVP"
      },
      "outputs": [],
      "source": [
        "train_x = np.zeros((len(x_train), 2048), dtype = np.float32)\n",
        "for f in range(train_x.shape[0]):\n",
        "  train_x[f] = smiles_to_array(x_train[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "dKhQc7EOKHMM"
      },
      "outputs": [],
      "source": [
        "valid_x = np.zeros((len(x_valid), 2048), dtype = np.float32)\n",
        "for f in range(valid_x.shape[0]):\n",
        "  valid_x[f] = smiles_to_array(x_valid[f])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "eSJBpQREMRYr"
      },
      "outputs": [],
      "source": [
        "test_x = np.zeros((len(x_test), 2048), dtype = np.float32)\n",
        "for f in range(test_x.shape[0]):\n",
        "  test_x[f] = smiles_to_array(x_test[f])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if there are overlaps\n",
        "overlap = []\n",
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "7rWxLD37banf"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(test_x.shape[0]):\n",
        "  for j in range(valid_x.shape[0]):\n",
        "    if np.array_equal(test_x[i], valid_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "gxflY746cryJ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(train_x.shape[0]):\n",
        "  for j in range(test_x.shape[0]):\n",
        "    if np.array_equal(train_x[i], test_x[j]) == True:\n",
        "      overlap.append((i,j))\n",
        "      print(i,j)"
      ],
      "metadata": {
        "id": "hbAAMsqPcr0y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "assert len(overlap) == 0"
      ],
      "metadata": {
        "id": "YNCJ9YgpoLTV"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "557ApFkFa6j7"
      },
      "outputs": [],
      "source": [
        "y_train = np.array(y_train).astype(int)\n",
        "y_valid = np.array(y_valid).astype(int)\n",
        "y_test = np.array(y_test).astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "eL24GiF7rCVF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2688e655-7bff-4e3a-b986-bc5a34146216"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "import gc               \n",
        "gc.collect() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KlcQEfe9M-VV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6e4dbc2-80ec-40b3-bb21-23bc7266e60f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 1.6526315789473685,\n",
              " 1: 0.47575757575757577,\n",
              " 2: 1.8470588235294119,\n",
              " 3: 0.5709090909090909,\n",
              " 4: 0.8722222222222222,\n",
              " 5: 1.8470588235294119,\n",
              " 6: 1.6526315789473685,\n",
              " 7: 1.8470588235294119,\n",
              " 8: 1.8470588235294119,\n",
              " 9: 1.7444444444444445,\n",
              " 10: 0.4131578947368421,\n",
              " 11: 1.4952380952380953,\n",
              " 12: 0.4025641025641026,\n",
              " 13: 1.3083333333333333,\n",
              " 14: 1.6526315789473685,\n",
              " 15: 1.57,\n",
              " 16: 1.7444444444444445,\n",
              " 17: 1.4952380952380953,\n",
              " 18: 1.256,\n",
              " 19: 1.4952380952380953,\n",
              " 20: 0.5322033898305085,\n",
              " 21: 1.0827586206896551,\n",
              " 22: 0.46865671641791046,\n",
              " 23: 1.6526315789473685,\n",
              " 24: 0.5607142857142857,\n",
              " 25: 1.9625,\n",
              " 26: 1.0129032258064516,\n",
              " 27: 0.628,\n",
              " 28: 1.1214285714285714,\n",
              " 29: 1.57,\n",
              " 30: 1.6526315789473685,\n",
              " 31: 1.6526315789473685,\n",
              " 32: 1.8470588235294119,\n",
              " 33: 1.162962962962963,\n",
              " 34: 1.6526315789473685,\n",
              " 35: 1.6526315789473685,\n",
              " 36: 0.9235294117647059,\n",
              " 37: 1.2076923076923076,\n",
              " 38: 0.6408163265306123,\n",
              " 39: 1.0129032258064516,\n",
              " 40: 0.6408163265306123,\n",
              " 41: 0.98125,\n",
              " 42: 0.8722222222222222,\n",
              " 43: 0.4186666666666667,\n",
              " 44: 1.4952380952380953,\n",
              " 45: 1.7444444444444445,\n",
              " 46: 1.57,\n",
              " 47: 1.7444444444444445,\n",
              " 48: 1.1214285714285714,\n",
              " 49: 0.9235294117647059}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "# Create class weights\n",
        "from sklearn.utils import class_weight\n",
        "y_unique = np.unique(np.array(y_train))\n",
        "class_weights = class_weight.compute_class_weight(class_weight = 'balanced', classes = y_unique,\n",
        "                y = np.array(y_train)) \n",
        "class_weights_dict45 = dict(enumerate(class_weights))\n",
        "class_weights_dict45"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "ta8ysiFqNkpJ"
      },
      "outputs": [],
      "source": [
        "# The architecture of model      \n",
        "import tensorflow as tf\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, Dense, Dropout\n",
        "num = len(set(df.MOA.tolist()))\n",
        "input1 = Input(shape=(train_x.shape[1],))\n",
        "layer = Dense(64, activation='relu')(input1)\n",
        "layer = Dropout(0.8)(layer)\n",
        "layer = Dense(num, activation='softmax')(layer)\n",
        "model1 = Model(inputs = input1, outputs = layer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ooDkEyMsNwkP"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "filepath_mlp = '/content/'+'MLP_50_MOA_weights.hdf5'\n",
        "checkpoint_mlp = ModelCheckpoint(filepath_mlp, monitor='val_accuracy', verbose=0, save_best_only = True,\n",
        "                mode = 'max')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Dt90GZzfOBar"
      },
      "outputs": [],
      "source": [
        "model1.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 1e-4),\n",
        "        loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "        metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "gFbTVo2qkIJh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60ca334b-1f7f-4eac-c4ef-a55ec2f6ddf8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25/25 - 1s - loss: 3.9564 - accuracy: 0.0242 - val_loss: 3.9124 - val_accuracy: 0.0204 - lr: 1.0000e-04 - 1s/epoch - 50ms/step\n",
            "Epoch 2/1800\n",
            "25/25 - 0s - loss: 3.9431 - accuracy: 0.0248 - val_loss: 3.9028 - val_accuracy: 0.0204 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 3/1800\n",
            "25/25 - 0s - loss: 3.9162 - accuracy: 0.0255 - val_loss: 3.8943 - val_accuracy: 0.0204 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 4/1800\n",
            "25/25 - 0s - loss: 3.8888 - accuracy: 0.0287 - val_loss: 3.8865 - val_accuracy: 0.0306 - lr: 1.0000e-04 - 120ms/epoch - 5ms/step\n",
            "Epoch 5/1800\n",
            "25/25 - 0s - loss: 3.8877 - accuracy: 0.0255 - val_loss: 3.8790 - val_accuracy: 0.0459 - lr: 1.0000e-04 - 110ms/epoch - 4ms/step\n",
            "Epoch 6/1800\n",
            "25/25 - 0s - loss: 3.8739 - accuracy: 0.0312 - val_loss: 3.8713 - val_accuracy: 0.0510 - lr: 1.0000e-04 - 116ms/epoch - 5ms/step\n",
            "Epoch 7/1800\n",
            "25/25 - 0s - loss: 3.8536 - accuracy: 0.0331 - val_loss: 3.8636 - val_accuracy: 0.0663 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 8/1800\n",
            "25/25 - 0s - loss: 3.8472 - accuracy: 0.0382 - val_loss: 3.8563 - val_accuracy: 0.0816 - lr: 1.0000e-04 - 137ms/epoch - 5ms/step\n",
            "Epoch 9/1800\n",
            "25/25 - 0s - loss: 3.8360 - accuracy: 0.0459 - val_loss: 3.8481 - val_accuracy: 0.0867 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 10/1800\n",
            "25/25 - 0s - loss: 3.8057 - accuracy: 0.0465 - val_loss: 3.8394 - val_accuracy: 0.0918 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 11/1800\n",
            "25/25 - 0s - loss: 3.7973 - accuracy: 0.0548 - val_loss: 3.8300 - val_accuracy: 0.1071 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 12/1800\n",
            "25/25 - 0s - loss: 3.7867 - accuracy: 0.0535 - val_loss: 3.8209 - val_accuracy: 0.1173 - lr: 1.0000e-04 - 110ms/epoch - 4ms/step\n",
            "Epoch 13/1800\n",
            "25/25 - 0s - loss: 3.7671 - accuracy: 0.0650 - val_loss: 3.8110 - val_accuracy: 0.1327 - lr: 1.0000e-04 - 119ms/epoch - 5ms/step\n",
            "Epoch 14/1800\n",
            "25/25 - 0s - loss: 3.7543 - accuracy: 0.0720 - val_loss: 3.8006 - val_accuracy: 0.1429 - lr: 1.0000e-04 - 133ms/epoch - 5ms/step\n",
            "Epoch 15/1800\n",
            "25/25 - 0s - loss: 3.7605 - accuracy: 0.0650 - val_loss: 3.7908 - val_accuracy: 0.1531 - lr: 1.0000e-04 - 116ms/epoch - 5ms/step\n",
            "Epoch 16/1800\n",
            "25/25 - 0s - loss: 3.7317 - accuracy: 0.0682 - val_loss: 3.7802 - val_accuracy: 0.1531 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 17/1800\n",
            "25/25 - 0s - loss: 3.7176 - accuracy: 0.0713 - val_loss: 3.7690 - val_accuracy: 0.1684 - lr: 1.0000e-04 - 118ms/epoch - 5ms/step\n",
            "Epoch 18/1800\n",
            "25/25 - 0s - loss: 3.7028 - accuracy: 0.0873 - val_loss: 3.7580 - val_accuracy: 0.1888 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 19/1800\n",
            "25/25 - 0s - loss: 3.6832 - accuracy: 0.0854 - val_loss: 3.7462 - val_accuracy: 0.1990 - lr: 1.0000e-04 - 123ms/epoch - 5ms/step\n",
            "Epoch 20/1800\n",
            "25/25 - 0s - loss: 3.6466 - accuracy: 0.0936 - val_loss: 3.7338 - val_accuracy: 0.2143 - lr: 1.0000e-04 - 120ms/epoch - 5ms/step\n",
            "Epoch 21/1800\n",
            "25/25 - 0s - loss: 3.6455 - accuracy: 0.1096 - val_loss: 3.7207 - val_accuracy: 0.2194 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 22/1800\n",
            "25/25 - 0s - loss: 3.6154 - accuracy: 0.1223 - val_loss: 3.7082 - val_accuracy: 0.2194 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 23/1800\n",
            "25/25 - 0s - loss: 3.6122 - accuracy: 0.0968 - val_loss: 3.6957 - val_accuracy: 0.2296 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 24/1800\n",
            "25/25 - 0s - loss: 3.5928 - accuracy: 0.1127 - val_loss: 3.6840 - val_accuracy: 0.2296 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 25/1800\n",
            "25/25 - 0s - loss: 3.5677 - accuracy: 0.1280 - val_loss: 3.6708 - val_accuracy: 0.2347 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 26/1800\n",
            "25/25 - 0s - loss: 3.5588 - accuracy: 0.1191 - val_loss: 3.6563 - val_accuracy: 0.2602 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 27/1800\n",
            "25/25 - 0s - loss: 3.5552 - accuracy: 0.1287 - val_loss: 3.6427 - val_accuracy: 0.2755 - lr: 1.0000e-04 - 118ms/epoch - 5ms/step\n",
            "Epoch 28/1800\n",
            "25/25 - 0s - loss: 3.5054 - accuracy: 0.1318 - val_loss: 3.6293 - val_accuracy: 0.2755 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 29/1800\n",
            "25/25 - 0s - loss: 3.4862 - accuracy: 0.1503 - val_loss: 3.6138 - val_accuracy: 0.2806 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 30/1800\n",
            "25/25 - 0s - loss: 3.4716 - accuracy: 0.1420 - val_loss: 3.5995 - val_accuracy: 0.2806 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 31/1800\n",
            "25/25 - 0s - loss: 3.4607 - accuracy: 0.1497 - val_loss: 3.5859 - val_accuracy: 0.2857 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 32/1800\n",
            "25/25 - 0s - loss: 3.4450 - accuracy: 0.1478 - val_loss: 3.5724 - val_accuracy: 0.2806 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 33/1800\n",
            "25/25 - 0s - loss: 3.4142 - accuracy: 0.1490 - val_loss: 3.5588 - val_accuracy: 0.2806 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 34/1800\n",
            "25/25 - 0s - loss: 3.4085 - accuracy: 0.1541 - val_loss: 3.5440 - val_accuracy: 0.2806 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 35/1800\n",
            "25/25 - 0s - loss: 3.3920 - accuracy: 0.1745 - val_loss: 3.5303 - val_accuracy: 0.2959 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 36/1800\n",
            "25/25 - 0s - loss: 3.3694 - accuracy: 0.1701 - val_loss: 3.5161 - val_accuracy: 0.3010 - lr: 1.0000e-04 - 110ms/epoch - 4ms/step\n",
            "Epoch 37/1800\n",
            "25/25 - 0s - loss: 3.3596 - accuracy: 0.1783 - val_loss: 3.5016 - val_accuracy: 0.3061 - lr: 1.0000e-04 - 116ms/epoch - 5ms/step\n",
            "Epoch 38/1800\n",
            "25/25 - 0s - loss: 3.3320 - accuracy: 0.1885 - val_loss: 3.4868 - val_accuracy: 0.3163 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 39/1800\n",
            "25/25 - 0s - loss: 3.3038 - accuracy: 0.1847 - val_loss: 3.4732 - val_accuracy: 0.3163 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 40/1800\n",
            "25/25 - 0s - loss: 3.3197 - accuracy: 0.1790 - val_loss: 3.4611 - val_accuracy: 0.3112 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 41/1800\n",
            "25/25 - 0s - loss: 3.2683 - accuracy: 0.1917 - val_loss: 3.4481 - val_accuracy: 0.3367 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 42/1800\n",
            "25/25 - 0s - loss: 3.2471 - accuracy: 0.1936 - val_loss: 3.4330 - val_accuracy: 0.3418 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 43/1800\n",
            "25/25 - 0s - loss: 3.2456 - accuracy: 0.1987 - val_loss: 3.4193 - val_accuracy: 0.3469 - lr: 1.0000e-04 - 117ms/epoch - 5ms/step\n",
            "Epoch 44/1800\n",
            "25/25 - 0s - loss: 3.2260 - accuracy: 0.1854 - val_loss: 3.4070 - val_accuracy: 0.3469 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 45/1800\n",
            "25/25 - 0s - loss: 3.1941 - accuracy: 0.2089 - val_loss: 3.3945 - val_accuracy: 0.3520 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 46/1800\n",
            "25/25 - 0s - loss: 3.1861 - accuracy: 0.2057 - val_loss: 3.3808 - val_accuracy: 0.3571 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 47/1800\n",
            "25/25 - 0s - loss: 3.1652 - accuracy: 0.1968 - val_loss: 3.3692 - val_accuracy: 0.3520 - lr: 1.0000e-04 - 96ms/epoch - 4ms/step\n",
            "Epoch 48/1800\n",
            "25/25 - 0s - loss: 3.1668 - accuracy: 0.2032 - val_loss: 3.3564 - val_accuracy: 0.3520 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 49/1800\n",
            "25/25 - 0s - loss: 3.1385 - accuracy: 0.2331 - val_loss: 3.3429 - val_accuracy: 0.3571 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 50/1800\n",
            "25/25 - 0s - loss: 3.1190 - accuracy: 0.2146 - val_loss: 3.3290 - val_accuracy: 0.3622 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 51/1800\n",
            "25/25 - 0s - loss: 3.1019 - accuracy: 0.2229 - val_loss: 3.3165 - val_accuracy: 0.3724 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 52/1800\n",
            "25/25 - 0s - loss: 3.1076 - accuracy: 0.2166 - val_loss: 3.3042 - val_accuracy: 0.3673 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 53/1800\n",
            "25/25 - 0s - loss: 3.0825 - accuracy: 0.2299 - val_loss: 3.2911 - val_accuracy: 0.3673 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 54/1800\n",
            "25/25 - 0s - loss: 3.0619 - accuracy: 0.2293 - val_loss: 3.2789 - val_accuracy: 0.3724 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 55/1800\n",
            "25/25 - 0s - loss: 3.0376 - accuracy: 0.2389 - val_loss: 3.2656 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 56/1800\n",
            "25/25 - 0s - loss: 2.9991 - accuracy: 0.2471 - val_loss: 3.2522 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 57/1800\n",
            "25/25 - 0s - loss: 2.9942 - accuracy: 0.2414 - val_loss: 3.2400 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 58/1800\n",
            "25/25 - 0s - loss: 2.9839 - accuracy: 0.2395 - val_loss: 3.2274 - val_accuracy: 0.3724 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 59/1800\n",
            "25/25 - 0s - loss: 3.0014 - accuracy: 0.2465 - val_loss: 3.2168 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 60/1800\n",
            "25/25 - 0s - loss: 2.9717 - accuracy: 0.2459 - val_loss: 3.2068 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 61/1800\n",
            "25/25 - 0s - loss: 2.9597 - accuracy: 0.2427 - val_loss: 3.1948 - val_accuracy: 0.3776 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 62/1800\n",
            "25/25 - 0s - loss: 2.9290 - accuracy: 0.2592 - val_loss: 3.1831 - val_accuracy: 0.3827 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 63/1800\n",
            "25/25 - 0s - loss: 2.9332 - accuracy: 0.2497 - val_loss: 3.1721 - val_accuracy: 0.3827 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 64/1800\n",
            "25/25 - 0s - loss: 2.9004 - accuracy: 0.2567 - val_loss: 3.1603 - val_accuracy: 0.3827 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 65/1800\n",
            "25/25 - 0s - loss: 2.8965 - accuracy: 0.2637 - val_loss: 3.1487 - val_accuracy: 0.4031 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 66/1800\n",
            "25/25 - 0s - loss: 2.8887 - accuracy: 0.2522 - val_loss: 3.1385 - val_accuracy: 0.4031 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 67/1800\n",
            "25/25 - 0s - loss: 2.8817 - accuracy: 0.2516 - val_loss: 3.1284 - val_accuracy: 0.4133 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 68/1800\n",
            "25/25 - 0s - loss: 2.8588 - accuracy: 0.2669 - val_loss: 3.1167 - val_accuracy: 0.4184 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 69/1800\n",
            "25/25 - 0s - loss: 2.8431 - accuracy: 0.2777 - val_loss: 3.1061 - val_accuracy: 0.4184 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 70/1800\n",
            "25/25 - 0s - loss: 2.8387 - accuracy: 0.2796 - val_loss: 3.0962 - val_accuracy: 0.4235 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 71/1800\n",
            "25/25 - 0s - loss: 2.8087 - accuracy: 0.2726 - val_loss: 3.0855 - val_accuracy: 0.4184 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 72/1800\n",
            "25/25 - 0s - loss: 2.8009 - accuracy: 0.2637 - val_loss: 3.0745 - val_accuracy: 0.4184 - lr: 1.0000e-04 - 96ms/epoch - 4ms/step\n",
            "Epoch 73/1800\n",
            "25/25 - 0s - loss: 2.8178 - accuracy: 0.2860 - val_loss: 3.0659 - val_accuracy: 0.4286 - lr: 1.0000e-04 - 108ms/epoch - 4ms/step\n",
            "Epoch 74/1800\n",
            "25/25 - 0s - loss: 2.7972 - accuracy: 0.2834 - val_loss: 3.0548 - val_accuracy: 0.4286 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 75/1800\n",
            "25/25 - 0s - loss: 2.7798 - accuracy: 0.2790 - val_loss: 3.0455 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 110ms/epoch - 4ms/step\n",
            "Epoch 76/1800\n",
            "25/25 - 0s - loss: 2.7825 - accuracy: 0.2777 - val_loss: 3.0350 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 77/1800\n",
            "25/25 - 0s - loss: 2.7213 - accuracy: 0.2879 - val_loss: 3.0252 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 78/1800\n",
            "25/25 - 0s - loss: 2.7386 - accuracy: 0.2943 - val_loss: 3.0158 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 79/1800\n",
            "25/25 - 0s - loss: 2.7313 - accuracy: 0.2885 - val_loss: 3.0072 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 80/1800\n",
            "25/25 - 0s - loss: 2.7231 - accuracy: 0.2911 - val_loss: 2.9979 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 81/1800\n",
            "25/25 - 0s - loss: 2.6820 - accuracy: 0.3006 - val_loss: 2.9888 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 82/1800\n",
            "25/25 - 0s - loss: 2.6959 - accuracy: 0.2955 - val_loss: 2.9795 - val_accuracy: 0.4286 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 83/1800\n",
            "25/25 - 0s - loss: 2.6813 - accuracy: 0.2987 - val_loss: 2.9708 - val_accuracy: 0.4388 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 84/1800\n",
            "25/25 - 0s - loss: 2.6445 - accuracy: 0.3146 - val_loss: 2.9607 - val_accuracy: 0.4439 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 85/1800\n",
            "25/25 - 0s - loss: 2.6227 - accuracy: 0.3166 - val_loss: 2.9516 - val_accuracy: 0.4337 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 86/1800\n",
            "25/25 - 0s - loss: 2.6368 - accuracy: 0.3191 - val_loss: 2.9411 - val_accuracy: 0.4439 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 87/1800\n",
            "25/25 - 0s - loss: 2.6113 - accuracy: 0.3102 - val_loss: 2.9321 - val_accuracy: 0.4388 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 88/1800\n",
            "25/25 - 0s - loss: 2.6415 - accuracy: 0.3070 - val_loss: 2.9240 - val_accuracy: 0.4439 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 89/1800\n",
            "25/25 - 0s - loss: 2.6132 - accuracy: 0.3159 - val_loss: 2.9162 - val_accuracy: 0.4439 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 90/1800\n",
            "25/25 - 0s - loss: 2.6441 - accuracy: 0.3064 - val_loss: 2.9074 - val_accuracy: 0.4490 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 91/1800\n",
            "25/25 - 0s - loss: 2.5607 - accuracy: 0.3242 - val_loss: 2.8980 - val_accuracy: 0.4541 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 92/1800\n",
            "25/25 - 0s - loss: 2.5911 - accuracy: 0.3153 - val_loss: 2.8894 - val_accuracy: 0.4541 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 93/1800\n",
            "25/25 - 0s - loss: 2.5566 - accuracy: 0.3115 - val_loss: 2.8819 - val_accuracy: 0.4541 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 94/1800\n",
            "25/25 - 0s - loss: 2.5713 - accuracy: 0.3223 - val_loss: 2.8747 - val_accuracy: 0.4541 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 95/1800\n",
            "25/25 - 0s - loss: 2.5553 - accuracy: 0.3293 - val_loss: 2.8671 - val_accuracy: 0.4541 - lr: 1.0000e-04 - 97ms/epoch - 4ms/step\n",
            "Epoch 96/1800\n",
            "25/25 - 0s - loss: 2.5535 - accuracy: 0.3236 - val_loss: 2.8572 - val_accuracy: 0.4592 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 97/1800\n",
            "25/25 - 0s - loss: 2.5566 - accuracy: 0.3210 - val_loss: 2.8488 - val_accuracy: 0.4592 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 98/1800\n",
            "25/25 - 0s - loss: 2.5613 - accuracy: 0.3166 - val_loss: 2.8425 - val_accuracy: 0.4592 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 99/1800\n",
            "25/25 - 0s - loss: 2.5543 - accuracy: 0.3287 - val_loss: 2.8355 - val_accuracy: 0.4643 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 100/1800\n",
            "25/25 - 0s - loss: 2.5124 - accuracy: 0.3293 - val_loss: 2.8281 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 101/1800\n",
            "25/25 - 0s - loss: 2.5150 - accuracy: 0.3166 - val_loss: 2.8214 - val_accuracy: 0.4694 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 102/1800\n",
            "25/25 - 0s - loss: 2.4971 - accuracy: 0.3382 - val_loss: 2.8138 - val_accuracy: 0.4643 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 103/1800\n",
            "25/25 - 0s - loss: 2.4730 - accuracy: 0.3439 - val_loss: 2.8062 - val_accuracy: 0.4694 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 104/1800\n",
            "25/25 - 0s - loss: 2.4727 - accuracy: 0.3306 - val_loss: 2.7992 - val_accuracy: 0.4694 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 105/1800\n",
            "25/25 - 0s - loss: 2.4423 - accuracy: 0.3446 - val_loss: 2.7912 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 106/1800\n",
            "25/25 - 0s - loss: 2.4058 - accuracy: 0.3541 - val_loss: 2.7817 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 107/1800\n",
            "25/25 - 0s - loss: 2.4348 - accuracy: 0.3408 - val_loss: 2.7747 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 108/1800\n",
            "25/25 - 0s - loss: 2.4314 - accuracy: 0.3516 - val_loss: 2.7686 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 109/1800\n",
            "25/25 - 0s - loss: 2.4393 - accuracy: 0.3510 - val_loss: 2.7614 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 110/1800\n",
            "25/25 - 0s - loss: 2.4331 - accuracy: 0.3325 - val_loss: 2.7538 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 111/1800\n",
            "25/25 - 0s - loss: 2.4238 - accuracy: 0.3624 - val_loss: 2.7463 - val_accuracy: 0.4745 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 112/1800\n",
            "25/25 - 0s - loss: 2.4209 - accuracy: 0.3567 - val_loss: 2.7394 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 113/1800\n",
            "25/25 - 0s - loss: 2.3976 - accuracy: 0.3446 - val_loss: 2.7325 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 114/1800\n",
            "25/25 - 0s - loss: 2.3554 - accuracy: 0.3783 - val_loss: 2.7245 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 115/1800\n",
            "25/25 - 0s - loss: 2.3823 - accuracy: 0.3522 - val_loss: 2.7192 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 116/1800\n",
            "25/25 - 0s - loss: 2.4000 - accuracy: 0.3490 - val_loss: 2.7130 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 117/1800\n",
            "25/25 - 0s - loss: 2.3301 - accuracy: 0.3707 - val_loss: 2.7065 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 118/1800\n",
            "25/25 - 0s - loss: 2.2956 - accuracy: 0.3720 - val_loss: 2.6999 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 119/1800\n",
            "25/25 - 0s - loss: 2.3189 - accuracy: 0.3631 - val_loss: 2.6936 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 120/1800\n",
            "25/25 - 0s - loss: 2.3463 - accuracy: 0.3573 - val_loss: 2.6870 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 121/1800\n",
            "25/25 - 0s - loss: 2.3512 - accuracy: 0.3592 - val_loss: 2.6810 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 122/1800\n",
            "25/25 - 0s - loss: 2.3613 - accuracy: 0.3567 - val_loss: 2.6748 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 123/1800\n",
            "25/25 - 0s - loss: 2.3346 - accuracy: 0.3586 - val_loss: 2.6690 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 124/1800\n",
            "25/25 - 0s - loss: 2.2858 - accuracy: 0.3904 - val_loss: 2.6637 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 125/1800\n",
            "25/25 - 0s - loss: 2.3084 - accuracy: 0.3822 - val_loss: 2.6571 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 126/1800\n",
            "25/25 - 0s - loss: 2.2876 - accuracy: 0.3682 - val_loss: 2.6494 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 127/1800\n",
            "25/25 - 0s - loss: 2.2599 - accuracy: 0.3739 - val_loss: 2.6441 - val_accuracy: 0.4796 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 128/1800\n",
            "25/25 - 0s - loss: 2.2729 - accuracy: 0.3860 - val_loss: 2.6382 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 129/1800\n",
            "25/25 - 0s - loss: 2.2554 - accuracy: 0.3828 - val_loss: 2.6325 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 130/1800\n",
            "25/25 - 0s - loss: 2.2366 - accuracy: 0.3917 - val_loss: 2.6263 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 131/1800\n",
            "25/25 - 0s - loss: 2.2671 - accuracy: 0.3752 - val_loss: 2.6209 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 132/1800\n",
            "25/25 - 0s - loss: 2.2348 - accuracy: 0.3796 - val_loss: 2.6138 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 133/1800\n",
            "25/25 - 0s - loss: 2.2285 - accuracy: 0.4006 - val_loss: 2.6090 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 134/1800\n",
            "25/25 - 0s - loss: 2.2115 - accuracy: 0.4057 - val_loss: 2.6016 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 135/1800\n",
            "25/25 - 0s - loss: 2.2606 - accuracy: 0.3548 - val_loss: 2.5974 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 136/1800\n",
            "25/25 - 0s - loss: 2.1706 - accuracy: 0.3924 - val_loss: 2.5925 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 137/1800\n",
            "25/25 - 0s - loss: 2.1671 - accuracy: 0.3828 - val_loss: 2.5865 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 138/1800\n",
            "25/25 - 0s - loss: 2.1866 - accuracy: 0.3987 - val_loss: 2.5822 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 139/1800\n",
            "25/25 - 0s - loss: 2.1708 - accuracy: 0.4115 - val_loss: 2.5766 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 140/1800\n",
            "25/25 - 0s - loss: 2.1753 - accuracy: 0.3981 - val_loss: 2.5714 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 141/1800\n",
            "25/25 - 0s - loss: 2.2093 - accuracy: 0.3987 - val_loss: 2.5678 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 142/1800\n",
            "25/25 - 0s - loss: 2.1833 - accuracy: 0.4070 - val_loss: 2.5622 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 143/1800\n",
            "25/25 - 0s - loss: 2.1886 - accuracy: 0.3885 - val_loss: 2.5561 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 144/1800\n",
            "25/25 - 0s - loss: 2.1737 - accuracy: 0.4025 - val_loss: 2.5510 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 145/1800\n",
            "25/25 - 0s - loss: 2.1370 - accuracy: 0.4006 - val_loss: 2.5461 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 146/1800\n",
            "25/25 - 0s - loss: 2.1333 - accuracy: 0.4146 - val_loss: 2.5411 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 147/1800\n",
            "25/25 - 0s - loss: 2.1620 - accuracy: 0.3936 - val_loss: 2.5353 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 148/1800\n",
            "25/25 - 0s - loss: 2.1638 - accuracy: 0.3943 - val_loss: 2.5307 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 149/1800\n",
            "25/25 - 0s - loss: 2.1098 - accuracy: 0.4115 - val_loss: 2.5252 - val_accuracy: 0.4847 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 150/1800\n",
            "25/25 - 0s - loss: 2.1003 - accuracy: 0.4242 - val_loss: 2.5199 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 151/1800\n",
            "25/25 - 0s - loss: 2.1199 - accuracy: 0.4064 - val_loss: 2.5148 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 152/1800\n",
            "25/25 - 0s - loss: 2.1033 - accuracy: 0.4000 - val_loss: 2.5106 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 153/1800\n",
            "25/25 - 0s - loss: 2.1812 - accuracy: 0.3955 - val_loss: 2.5062 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 154/1800\n",
            "25/25 - 0s - loss: 2.0844 - accuracy: 0.4191 - val_loss: 2.5004 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 155/1800\n",
            "25/25 - 0s - loss: 2.0992 - accuracy: 0.4242 - val_loss: 2.4940 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 156/1800\n",
            "25/25 - 0s - loss: 2.0995 - accuracy: 0.4127 - val_loss: 2.4890 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 157/1800\n",
            "25/25 - 0s - loss: 2.0775 - accuracy: 0.4134 - val_loss: 2.4851 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 158/1800\n",
            "25/25 - 0s - loss: 2.0664 - accuracy: 0.4178 - val_loss: 2.4809 - val_accuracy: 0.4898 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 159/1800\n",
            "25/25 - 0s - loss: 2.0469 - accuracy: 0.4325 - val_loss: 2.4756 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 160/1800\n",
            "25/25 - 0s - loss: 2.0656 - accuracy: 0.4089 - val_loss: 2.4707 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 161/1800\n",
            "25/25 - 0s - loss: 2.0634 - accuracy: 0.4261 - val_loss: 2.4663 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 162/1800\n",
            "25/25 - 0s - loss: 2.0260 - accuracy: 0.4344 - val_loss: 2.4620 - val_accuracy: 0.4949 - lr: 1.0000e-04 - 97ms/epoch - 4ms/step\n",
            "Epoch 163/1800\n",
            "25/25 - 0s - loss: 2.0244 - accuracy: 0.4382 - val_loss: 2.4571 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 164/1800\n",
            "25/25 - 0s - loss: 2.0668 - accuracy: 0.4045 - val_loss: 2.4534 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 165/1800\n",
            "25/25 - 0s - loss: 2.0294 - accuracy: 0.4153 - val_loss: 2.4499 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 166/1800\n",
            "25/25 - 0s - loss: 1.9877 - accuracy: 0.4306 - val_loss: 2.4454 - val_accuracy: 0.5000 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 167/1800\n",
            "25/25 - 0s - loss: 1.9953 - accuracy: 0.4248 - val_loss: 2.4406 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 168/1800\n",
            "25/25 - 0s - loss: 2.0245 - accuracy: 0.4255 - val_loss: 2.4371 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 169/1800\n",
            "25/25 - 0s - loss: 1.9925 - accuracy: 0.4178 - val_loss: 2.4333 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 170/1800\n",
            "25/25 - 0s - loss: 1.9583 - accuracy: 0.4369 - val_loss: 2.4274 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 171/1800\n",
            "25/25 - 0s - loss: 1.9868 - accuracy: 0.4382 - val_loss: 2.4230 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 172/1800\n",
            "25/25 - 0s - loss: 1.9817 - accuracy: 0.4357 - val_loss: 2.4195 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 173/1800\n",
            "25/25 - 0s - loss: 1.9495 - accuracy: 0.4433 - val_loss: 2.4158 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 174/1800\n",
            "25/25 - 0s - loss: 1.9505 - accuracy: 0.4605 - val_loss: 2.4115 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 175/1800\n",
            "25/25 - 0s - loss: 1.9621 - accuracy: 0.4446 - val_loss: 2.4083 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 176/1800\n",
            "25/25 - 0s - loss: 1.9578 - accuracy: 0.4439 - val_loss: 2.4037 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 177/1800\n",
            "25/25 - 0s - loss: 1.9601 - accuracy: 0.4414 - val_loss: 2.4000 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 178/1800\n",
            "25/25 - 0s - loss: 1.9533 - accuracy: 0.4465 - val_loss: 2.3952 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 179/1800\n",
            "25/25 - 0s - loss: 1.9476 - accuracy: 0.4318 - val_loss: 2.3918 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 180/1800\n",
            "25/25 - 0s - loss: 2.0080 - accuracy: 0.4178 - val_loss: 2.3883 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 181/1800\n",
            "25/25 - 0s - loss: 1.9365 - accuracy: 0.4369 - val_loss: 2.3850 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 96ms/epoch - 4ms/step\n",
            "Epoch 182/1800\n",
            "25/25 - 0s - loss: 1.9547 - accuracy: 0.4497 - val_loss: 2.3814 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 183/1800\n",
            "25/25 - 0s - loss: 1.8741 - accuracy: 0.4656 - val_loss: 2.3776 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 184/1800\n",
            "25/25 - 0s - loss: 1.8985 - accuracy: 0.4554 - val_loss: 2.3728 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 185/1800\n",
            "25/25 - 0s - loss: 1.9027 - accuracy: 0.4548 - val_loss: 2.3687 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 186/1800\n",
            "25/25 - 0s - loss: 1.9273 - accuracy: 0.4446 - val_loss: 2.3643 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 187/1800\n",
            "25/25 - 0s - loss: 1.8742 - accuracy: 0.4503 - val_loss: 2.3599 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 188/1800\n",
            "25/25 - 0s - loss: 1.8454 - accuracy: 0.4586 - val_loss: 2.3554 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 189/1800\n",
            "25/25 - 0s - loss: 1.8804 - accuracy: 0.4592 - val_loss: 2.3530 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 190/1800\n",
            "25/25 - 0s - loss: 1.8878 - accuracy: 0.4427 - val_loss: 2.3492 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 191/1800\n",
            "25/25 - 0s - loss: 1.8585 - accuracy: 0.4631 - val_loss: 2.3462 - val_accuracy: 0.5153 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 192/1800\n",
            "25/25 - 0s - loss: 1.9206 - accuracy: 0.4414 - val_loss: 2.3428 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 193/1800\n",
            "25/25 - 0s - loss: 1.9021 - accuracy: 0.4656 - val_loss: 2.3404 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 194/1800\n",
            "25/25 - 0s - loss: 1.8575 - accuracy: 0.4312 - val_loss: 2.3363 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 195/1800\n",
            "25/25 - 0s - loss: 1.8278 - accuracy: 0.4650 - val_loss: 2.3323 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 196/1800\n",
            "25/25 - 0s - loss: 1.8600 - accuracy: 0.4611 - val_loss: 2.3294 - val_accuracy: 0.5051 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 197/1800\n",
            "25/25 - 0s - loss: 1.7965 - accuracy: 0.4847 - val_loss: 2.3238 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 198/1800\n",
            "25/25 - 0s - loss: 1.8505 - accuracy: 0.4503 - val_loss: 2.3206 - val_accuracy: 0.5102 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 199/1800\n",
            "25/25 - 0s - loss: 1.8192 - accuracy: 0.4662 - val_loss: 2.3177 - val_accuracy: 0.5153 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 200/1800\n",
            "25/25 - 0s - loss: 1.8574 - accuracy: 0.4490 - val_loss: 2.3162 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 201/1800\n",
            "25/25 - 0s - loss: 1.8343 - accuracy: 0.4580 - val_loss: 2.3134 - val_accuracy: 0.5255 - lr: 1.0000e-04 - 115ms/epoch - 5ms/step\n",
            "Epoch 202/1800\n",
            "25/25 - 0s - loss: 1.8533 - accuracy: 0.4465 - val_loss: 2.3106 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 203/1800\n",
            "25/25 - 0s - loss: 1.7974 - accuracy: 0.4732 - val_loss: 2.3082 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 204/1800\n",
            "25/25 - 0s - loss: 1.8073 - accuracy: 0.4771 - val_loss: 2.3046 - val_accuracy: 0.5153 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 205/1800\n",
            "25/25 - 0s - loss: 1.7643 - accuracy: 0.4764 - val_loss: 2.3011 - val_accuracy: 0.5153 - lr: 1.0000e-04 - 97ms/epoch - 4ms/step\n",
            "Epoch 206/1800\n",
            "25/25 - 0s - loss: 1.7602 - accuracy: 0.4873 - val_loss: 2.2963 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 207/1800\n",
            "25/25 - 0s - loss: 1.7903 - accuracy: 0.4834 - val_loss: 2.2930 - val_accuracy: 0.5153 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 208/1800\n",
            "25/25 - 0s - loss: 1.7843 - accuracy: 0.4771 - val_loss: 2.2905 - val_accuracy: 0.5255 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 209/1800\n",
            "25/25 - 0s - loss: 1.7879 - accuracy: 0.4739 - val_loss: 2.2879 - val_accuracy: 0.5255 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 210/1800\n",
            "25/25 - 0s - loss: 1.7879 - accuracy: 0.4790 - val_loss: 2.2845 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 211/1800\n",
            "25/25 - 0s - loss: 1.7742 - accuracy: 0.4707 - val_loss: 2.2814 - val_accuracy: 0.5204 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 212/1800\n",
            "25/25 - 0s - loss: 1.7921 - accuracy: 0.4713 - val_loss: 2.2785 - val_accuracy: 0.5255 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 213/1800\n",
            "25/25 - 0s - loss: 1.7486 - accuracy: 0.4892 - val_loss: 2.2746 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 114ms/epoch - 5ms/step\n",
            "Epoch 214/1800\n",
            "25/25 - 0s - loss: 1.7861 - accuracy: 0.4758 - val_loss: 2.2710 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 215/1800\n",
            "25/25 - 0s - loss: 1.7409 - accuracy: 0.4764 - val_loss: 2.2692 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 216/1800\n",
            "25/25 - 0s - loss: 1.7719 - accuracy: 0.4777 - val_loss: 2.2658 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 217/1800\n",
            "25/25 - 0s - loss: 1.7496 - accuracy: 0.4885 - val_loss: 2.2625 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 218/1800\n",
            "25/25 - 0s - loss: 1.7700 - accuracy: 0.4745 - val_loss: 2.2604 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 219/1800\n",
            "25/25 - 0s - loss: 1.7057 - accuracy: 0.4924 - val_loss: 2.2572 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 220/1800\n",
            "25/25 - 0s - loss: 1.7584 - accuracy: 0.4713 - val_loss: 2.2539 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 221/1800\n",
            "25/25 - 0s - loss: 1.7524 - accuracy: 0.4777 - val_loss: 2.2516 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 222/1800\n",
            "25/25 - 0s - loss: 1.7422 - accuracy: 0.4860 - val_loss: 2.2491 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 223/1800\n",
            "25/25 - 0s - loss: 1.7776 - accuracy: 0.4713 - val_loss: 2.2469 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 224/1800\n",
            "25/25 - 0s - loss: 1.7519 - accuracy: 0.4701 - val_loss: 2.2441 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 225/1800\n",
            "25/25 - 0s - loss: 1.7113 - accuracy: 0.4828 - val_loss: 2.2413 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 226/1800\n",
            "25/25 - 0s - loss: 1.6833 - accuracy: 0.5083 - val_loss: 2.2375 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 227/1800\n",
            "25/25 - 0s - loss: 1.7123 - accuracy: 0.4777 - val_loss: 2.2347 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 228/1800\n",
            "25/25 - 0s - loss: 1.7275 - accuracy: 0.4841 - val_loss: 2.2323 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 229/1800\n",
            "25/25 - 0s - loss: 1.7042 - accuracy: 0.4777 - val_loss: 2.2313 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 230/1800\n",
            "25/25 - 0s - loss: 1.6969 - accuracy: 0.4809 - val_loss: 2.2287 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 231/1800\n",
            "25/25 - 0s - loss: 1.6706 - accuracy: 0.4854 - val_loss: 2.2246 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 232/1800\n",
            "25/25 - 0s - loss: 1.6460 - accuracy: 0.5019 - val_loss: 2.2228 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 233/1800\n",
            "25/25 - 0s - loss: 1.7452 - accuracy: 0.4624 - val_loss: 2.2209 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 234/1800\n",
            "25/25 - 0s - loss: 1.6617 - accuracy: 0.5025 - val_loss: 2.2179 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 235/1800\n",
            "25/25 - 0s - loss: 1.6598 - accuracy: 0.5000 - val_loss: 2.2151 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 236/1800\n",
            "25/25 - 0s - loss: 1.6710 - accuracy: 0.4994 - val_loss: 2.2126 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 237/1800\n",
            "25/25 - 0s - loss: 1.6649 - accuracy: 0.4892 - val_loss: 2.2098 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 116ms/epoch - 5ms/step\n",
            "Epoch 238/1800\n",
            "25/25 - 0s - loss: 1.6796 - accuracy: 0.5064 - val_loss: 2.2080 - val_accuracy: 0.5306 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 239/1800\n",
            "25/25 - 0s - loss: 1.7015 - accuracy: 0.4847 - val_loss: 2.2059 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 240/1800\n",
            "25/25 - 0s - loss: 1.7064 - accuracy: 0.4847 - val_loss: 2.2031 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 98ms/epoch - 4ms/step\n",
            "Epoch 241/1800\n",
            "25/25 - 0s - loss: 1.6140 - accuracy: 0.5019 - val_loss: 2.2003 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 242/1800\n",
            "25/25 - 0s - loss: 1.6141 - accuracy: 0.5070 - val_loss: 2.1971 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 111ms/epoch - 4ms/step\n",
            "Epoch 243/1800\n",
            "25/25 - 0s - loss: 1.6262 - accuracy: 0.5057 - val_loss: 2.1954 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 244/1800\n",
            "25/25 - 0s - loss: 1.6917 - accuracy: 0.4675 - val_loss: 2.1934 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 245/1800\n",
            "25/25 - 0s - loss: 1.6636 - accuracy: 0.4994 - val_loss: 2.1909 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 246/1800\n",
            "25/25 - 0s - loss: 1.6427 - accuracy: 0.5025 - val_loss: 2.1894 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 247/1800\n",
            "25/25 - 0s - loss: 1.6535 - accuracy: 0.5006 - val_loss: 2.1879 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 248/1800\n",
            "25/25 - 0s - loss: 1.5905 - accuracy: 0.5064 - val_loss: 2.1849 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 112ms/epoch - 4ms/step\n",
            "Epoch 249/1800\n",
            "25/25 - 0s - loss: 1.6250 - accuracy: 0.5051 - val_loss: 2.1827 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 250/1800\n",
            "25/25 - 0s - loss: 1.5727 - accuracy: 0.5204 - val_loss: 2.1794 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 251/1800\n",
            "25/25 - 0s - loss: 1.6239 - accuracy: 0.5185 - val_loss: 2.1771 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 252/1800\n",
            "25/25 - 0s - loss: 1.6078 - accuracy: 0.5146 - val_loss: 2.1757 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 253/1800\n",
            "25/25 - 0s - loss: 1.5880 - accuracy: 0.5146 - val_loss: 2.1726 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 254/1800\n",
            "25/25 - 0s - loss: 1.6093 - accuracy: 0.5083 - val_loss: 2.1701 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 255/1800\n",
            "25/25 - 0s - loss: 1.5624 - accuracy: 0.5159 - val_loss: 2.1685 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 256/1800\n",
            "25/25 - 0s - loss: 1.6024 - accuracy: 0.5032 - val_loss: 2.1659 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 257/1800\n",
            "25/25 - 0s - loss: 1.5657 - accuracy: 0.5350 - val_loss: 2.1648 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 258/1800\n",
            "25/25 - 0s - loss: 1.6209 - accuracy: 0.4911 - val_loss: 2.1631 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 259/1800\n",
            "25/25 - 0s - loss: 1.5929 - accuracy: 0.5172 - val_loss: 2.1614 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 260/1800\n",
            "25/25 - 0s - loss: 1.5776 - accuracy: 0.5223 - val_loss: 2.1586 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 261/1800\n",
            "25/25 - 0s - loss: 1.5479 - accuracy: 0.5172 - val_loss: 2.1556 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 262/1800\n",
            "25/25 - 0s - loss: 1.5255 - accuracy: 0.5389 - val_loss: 2.1531 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 263/1800\n",
            "25/25 - 0s - loss: 1.5755 - accuracy: 0.5210 - val_loss: 2.1518 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 264/1800\n",
            "25/25 - 0s - loss: 1.6131 - accuracy: 0.5013 - val_loss: 2.1504 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 265/1800\n",
            "25/25 - 0s - loss: 1.5713 - accuracy: 0.5025 - val_loss: 2.1488 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 86ms/epoch - 3ms/step\n",
            "Epoch 266/1800\n",
            "25/25 - 0s - loss: 1.5707 - accuracy: 0.5166 - val_loss: 2.1473 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 267/1800\n",
            "25/25 - 0s - loss: 1.5253 - accuracy: 0.5255 - val_loss: 2.1459 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 268/1800\n",
            "25/25 - 0s - loss: 1.5641 - accuracy: 0.5293 - val_loss: 2.1435 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 269/1800\n",
            "25/25 - 0s - loss: 1.5156 - accuracy: 0.5134 - val_loss: 2.1418 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 270/1800\n",
            "25/25 - 0s - loss: 1.5722 - accuracy: 0.5083 - val_loss: 2.1400 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 271/1800\n",
            "25/25 - 0s - loss: 1.4973 - accuracy: 0.5318 - val_loss: 2.1384 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 272/1800\n",
            "25/25 - 0s - loss: 1.5197 - accuracy: 0.5248 - val_loss: 2.1361 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 273/1800\n",
            "25/25 - 0s - loss: 1.5148 - accuracy: 0.5210 - val_loss: 2.1346 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 274/1800\n",
            "25/25 - 0s - loss: 1.5462 - accuracy: 0.5242 - val_loss: 2.1331 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 275/1800\n",
            "25/25 - 0s - loss: 1.5318 - accuracy: 0.5153 - val_loss: 2.1316 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 276/1800\n",
            "25/25 - 0s - loss: 1.4898 - accuracy: 0.5395 - val_loss: 2.1297 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 277/1800\n",
            "25/25 - 0s - loss: 1.5027 - accuracy: 0.5178 - val_loss: 2.1280 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 278/1800\n",
            "25/25 - 0s - loss: 1.5565 - accuracy: 0.5172 - val_loss: 2.1258 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 279/1800\n",
            "25/25 - 0s - loss: 1.5006 - accuracy: 0.5350 - val_loss: 2.1237 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 280/1800\n",
            "25/25 - 0s - loss: 1.4360 - accuracy: 0.5548 - val_loss: 2.1224 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 281/1800\n",
            "25/25 - 0s - loss: 1.5161 - accuracy: 0.5248 - val_loss: 2.1218 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 282/1800\n",
            "25/25 - 0s - loss: 1.4587 - accuracy: 0.5471 - val_loss: 2.1198 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 283/1800\n",
            "25/25 - 0s - loss: 1.4946 - accuracy: 0.5414 - val_loss: 2.1183 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 284/1800\n",
            "25/25 - 0s - loss: 1.5179 - accuracy: 0.5045 - val_loss: 2.1172 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 285/1800\n",
            "25/25 - 0s - loss: 1.5439 - accuracy: 0.5331 - val_loss: 2.1163 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 286/1800\n",
            "25/25 - 0s - loss: 1.5335 - accuracy: 0.5229 - val_loss: 2.1149 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 287/1800\n",
            "25/25 - 0s - loss: 1.5237 - accuracy: 0.5242 - val_loss: 2.1141 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 288/1800\n",
            "25/25 - 0s - loss: 1.4944 - accuracy: 0.5261 - val_loss: 2.1125 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 289/1800\n",
            "25/25 - 0s - loss: 1.5030 - accuracy: 0.5363 - val_loss: 2.1117 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 290/1800\n",
            "25/25 - 0s - loss: 1.5205 - accuracy: 0.5204 - val_loss: 2.1096 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 291/1800\n",
            "25/25 - 0s - loss: 1.4770 - accuracy: 0.5541 - val_loss: 2.1073 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 292/1800\n",
            "25/25 - 0s - loss: 1.4483 - accuracy: 0.5459 - val_loss: 2.1058 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 293/1800\n",
            "25/25 - 0s - loss: 1.4876 - accuracy: 0.5459 - val_loss: 2.1050 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 294/1800\n",
            "25/25 - 0s - loss: 1.4913 - accuracy: 0.5363 - val_loss: 2.1039 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 295/1800\n",
            "25/25 - 0s - loss: 1.4248 - accuracy: 0.5439 - val_loss: 2.1022 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 296/1800\n",
            "25/25 - 0s - loss: 1.4578 - accuracy: 0.5325 - val_loss: 2.1015 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 297/1800\n",
            "25/25 - 0s - loss: 1.4579 - accuracy: 0.5471 - val_loss: 2.0993 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 298/1800\n",
            "25/25 - 0s - loss: 1.4315 - accuracy: 0.5561 - val_loss: 2.0984 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 299/1800\n",
            "25/25 - 0s - loss: 1.4845 - accuracy: 0.5446 - val_loss: 2.0964 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 300/1800\n",
            "25/25 - 0s - loss: 1.4827 - accuracy: 0.5452 - val_loss: 2.0955 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 301/1800\n",
            "25/25 - 0s - loss: 1.4527 - accuracy: 0.5248 - val_loss: 2.0945 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 302/1800\n",
            "25/25 - 0s - loss: 1.3949 - accuracy: 0.5510 - val_loss: 2.0932 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 303/1800\n",
            "25/25 - 0s - loss: 1.4016 - accuracy: 0.5586 - val_loss: 2.0914 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 304/1800\n",
            "25/25 - 0s - loss: 1.4248 - accuracy: 0.5478 - val_loss: 2.0902 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 305/1800\n",
            "25/25 - 0s - loss: 1.4424 - accuracy: 0.5522 - val_loss: 2.0898 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 306/1800\n",
            "25/25 - 0s - loss: 1.4230 - accuracy: 0.5529 - val_loss: 2.0894 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 307/1800\n",
            "25/25 - 0s - loss: 1.4162 - accuracy: 0.5624 - val_loss: 2.0881 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 308/1800\n",
            "25/25 - 0s - loss: 1.4346 - accuracy: 0.5510 - val_loss: 2.0873 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 309/1800\n",
            "25/25 - 0s - loss: 1.4053 - accuracy: 0.5694 - val_loss: 2.0858 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 310/1800\n",
            "25/25 - 0s - loss: 1.4138 - accuracy: 0.5452 - val_loss: 2.0851 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 311/1800\n",
            "25/25 - 0s - loss: 1.4176 - accuracy: 0.5401 - val_loss: 2.0839 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 312/1800\n",
            "25/25 - 0s - loss: 1.4108 - accuracy: 0.5624 - val_loss: 2.0832 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 313/1800\n",
            "25/25 - 0s - loss: 1.4163 - accuracy: 0.5497 - val_loss: 2.0822 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 314/1800\n",
            "25/25 - 0s - loss: 1.4116 - accuracy: 0.5490 - val_loss: 2.0809 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 315/1800\n",
            "25/25 - 0s - loss: 1.3997 - accuracy: 0.5732 - val_loss: 2.0788 - val_accuracy: 0.5510 - lr: 1.0000e-04 - 113ms/epoch - 5ms/step\n",
            "Epoch 316/1800\n",
            "25/25 - 0s - loss: 1.3719 - accuracy: 0.5650 - val_loss: 2.0777 - val_accuracy: 0.5510 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 317/1800\n",
            "25/25 - 0s - loss: 1.3261 - accuracy: 0.5790 - val_loss: 2.0767 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 318/1800\n",
            "25/25 - 0s - loss: 1.3606 - accuracy: 0.5650 - val_loss: 2.0751 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 319/1800\n",
            "25/25 - 0s - loss: 1.3556 - accuracy: 0.5656 - val_loss: 2.0740 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 320/1800\n",
            "25/25 - 0s - loss: 1.4276 - accuracy: 0.5465 - val_loss: 2.0741 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 321/1800\n",
            "25/25 - 0s - loss: 1.4354 - accuracy: 0.5427 - val_loss: 2.0723 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 97ms/epoch - 4ms/step\n",
            "Epoch 322/1800\n",
            "25/25 - 0s - loss: 1.4468 - accuracy: 0.5293 - val_loss: 2.0719 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 323/1800\n",
            "25/25 - 0s - loss: 1.4130 - accuracy: 0.5452 - val_loss: 2.0717 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 324/1800\n",
            "25/25 - 0s - loss: 1.3811 - accuracy: 0.5567 - val_loss: 2.0709 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 325/1800\n",
            "25/25 - 0s - loss: 1.3853 - accuracy: 0.5439 - val_loss: 2.0697 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 326/1800\n",
            "25/25 - 0s - loss: 1.4267 - accuracy: 0.5427 - val_loss: 2.0683 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 327/1800\n",
            "25/25 - 0s - loss: 1.3800 - accuracy: 0.5567 - val_loss: 2.0660 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 328/1800\n",
            "25/25 - 0s - loss: 1.4195 - accuracy: 0.5561 - val_loss: 2.0652 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 329/1800\n",
            "25/25 - 0s - loss: 1.3289 - accuracy: 0.5739 - val_loss: 2.0646 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 330/1800\n",
            "25/25 - 0s - loss: 1.3511 - accuracy: 0.5688 - val_loss: 2.0627 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 331/1800\n",
            "25/25 - 0s - loss: 1.3689 - accuracy: 0.5535 - val_loss: 2.0626 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 332/1800\n",
            "25/25 - 0s - loss: 1.3703 - accuracy: 0.5726 - val_loss: 2.0616 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 333/1800\n",
            "25/25 - 0s - loss: 1.3583 - accuracy: 0.5694 - val_loss: 2.0606 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 334/1800\n",
            "25/25 - 0s - loss: 1.3917 - accuracy: 0.5478 - val_loss: 2.0593 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 335/1800\n",
            "25/25 - 0s - loss: 1.3745 - accuracy: 0.5529 - val_loss: 2.0586 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 336/1800\n",
            "25/25 - 0s - loss: 1.3363 - accuracy: 0.5567 - val_loss: 2.0587 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 337/1800\n",
            "25/25 - 0s - loss: 1.3270 - accuracy: 0.5707 - val_loss: 2.0585 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 338/1800\n",
            "25/25 - 0s - loss: 1.3491 - accuracy: 0.5484 - val_loss: 2.0582 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 339/1800\n",
            "25/25 - 0s - loss: 1.3551 - accuracy: 0.5669 - val_loss: 2.0574 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 340/1800\n",
            "25/25 - 0s - loss: 1.3975 - accuracy: 0.5567 - val_loss: 2.0570 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 341/1800\n",
            "25/25 - 0s - loss: 1.3851 - accuracy: 0.5369 - val_loss: 2.0569 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 342/1800\n",
            "25/25 - 0s - loss: 1.2954 - accuracy: 0.5879 - val_loss: 2.0569 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 343/1800\n",
            "25/25 - 0s - loss: 1.3333 - accuracy: 0.5669 - val_loss: 2.0569 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 344/1800\n",
            "25/25 - 0s - loss: 1.2757 - accuracy: 0.5815 - val_loss: 2.0562 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 95ms/epoch - 4ms/step\n",
            "Epoch 345/1800\n",
            "25/25 - 0s - loss: 1.3205 - accuracy: 0.5580 - val_loss: 2.0552 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 97ms/epoch - 4ms/step\n",
            "Epoch 346/1800\n",
            "25/25 - 0s - loss: 1.2857 - accuracy: 0.5828 - val_loss: 2.0553 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 347/1800\n",
            "25/25 - 0s - loss: 1.3406 - accuracy: 0.5682 - val_loss: 2.0557 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 348/1800\n",
            "25/25 - 0s - loss: 1.2974 - accuracy: 0.5631 - val_loss: 2.0553 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 349/1800\n",
            "25/25 - 0s - loss: 1.3021 - accuracy: 0.5854 - val_loss: 2.0550 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 350/1800\n",
            "25/25 - 0s - loss: 1.3562 - accuracy: 0.5713 - val_loss: 2.0542 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 351/1800\n",
            "25/25 - 0s - loss: 1.3064 - accuracy: 0.5573 - val_loss: 2.0526 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 352/1800\n",
            "25/25 - 0s - loss: 1.3113 - accuracy: 0.5713 - val_loss: 2.0527 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 353/1800\n",
            "25/25 - 0s - loss: 1.3232 - accuracy: 0.5739 - val_loss: 2.0521 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 354/1800\n",
            "25/25 - 0s - loss: 1.2626 - accuracy: 0.6013 - val_loss: 2.0515 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 355/1800\n",
            "25/25 - 0s - loss: 1.2949 - accuracy: 0.5669 - val_loss: 2.0510 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 356/1800\n",
            "25/25 - 0s - loss: 1.2851 - accuracy: 0.5771 - val_loss: 2.0494 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 357/1800\n",
            "25/25 - 0s - loss: 1.3054 - accuracy: 0.5675 - val_loss: 2.0492 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 358/1800\n",
            "25/25 - 0s - loss: 1.3243 - accuracy: 0.5682 - val_loss: 2.0482 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 359/1800\n",
            "25/25 - 0s - loss: 1.2419 - accuracy: 0.6051 - val_loss: 2.0478 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 360/1800\n",
            "25/25 - 0s - loss: 1.2819 - accuracy: 0.5720 - val_loss: 2.0470 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 361/1800\n",
            "25/25 - 0s - loss: 1.2724 - accuracy: 0.5777 - val_loss: 2.0460 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 362/1800\n",
            "25/25 - 0s - loss: 1.2845 - accuracy: 0.5777 - val_loss: 2.0459 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 363/1800\n",
            "25/25 - 0s - loss: 1.3239 - accuracy: 0.5790 - val_loss: 2.0458 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 364/1800\n",
            "25/25 - 0s - loss: 1.2849 - accuracy: 0.5726 - val_loss: 2.0456 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 365/1800\n",
            "25/25 - 0s - loss: 1.2606 - accuracy: 0.5803 - val_loss: 2.0457 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 366/1800\n",
            "25/25 - 0s - loss: 1.2629 - accuracy: 0.5930 - val_loss: 2.0456 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 86ms/epoch - 3ms/step\n",
            "Epoch 367/1800\n",
            "25/25 - 0s - loss: 1.2945 - accuracy: 0.5809 - val_loss: 2.0460 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 368/1800\n",
            "25/25 - 0s - loss: 1.2923 - accuracy: 0.5643 - val_loss: 2.0456 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 369/1800\n",
            "25/25 - 0s - loss: 1.2540 - accuracy: 0.5822 - val_loss: 2.0444 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 370/1800\n",
            "25/25 - 0s - loss: 1.2688 - accuracy: 0.5892 - val_loss: 2.0439 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 371/1800\n",
            "25/25 - 0s - loss: 1.2690 - accuracy: 0.5841 - val_loss: 2.0438 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 372/1800\n",
            "25/25 - 0s - loss: 1.2872 - accuracy: 0.5745 - val_loss: 2.0446 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 373/1800\n",
            "25/25 - 0s - loss: 1.3188 - accuracy: 0.5764 - val_loss: 2.0444 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 374/1800\n",
            "25/25 - 0s - loss: 1.2812 - accuracy: 0.5911 - val_loss: 2.0437 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 375/1800\n",
            "25/25 - 0s - loss: 1.2541 - accuracy: 0.5975 - val_loss: 2.0436 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 376/1800\n",
            "25/25 - 0s - loss: 1.2784 - accuracy: 0.5828 - val_loss: 2.0447 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 96ms/epoch - 4ms/step\n",
            "Epoch 377/1800\n",
            "25/25 - 0s - loss: 1.2086 - accuracy: 0.6000 - val_loss: 2.0451 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 378/1800\n",
            "25/25 - 0s - loss: 1.2550 - accuracy: 0.5917 - val_loss: 2.0448 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 379/1800\n",
            "25/25 - 0s - loss: 1.2532 - accuracy: 0.5866 - val_loss: 2.0443 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 380/1800\n",
            "25/25 - 0s - loss: 1.2364 - accuracy: 0.5911 - val_loss: 2.0430 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 381/1800\n",
            "25/25 - 0s - loss: 1.2274 - accuracy: 0.6006 - val_loss: 2.0438 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 382/1800\n",
            "25/25 - 0s - loss: 1.2613 - accuracy: 0.5879 - val_loss: 2.0441 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 93ms/epoch - 4ms/step\n",
            "Epoch 383/1800\n",
            "25/25 - 0s - loss: 1.2826 - accuracy: 0.5834 - val_loss: 2.0433 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 384/1800\n",
            "25/25 - 0s - loss: 1.2745 - accuracy: 0.5866 - val_loss: 2.0427 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 385/1800\n",
            "25/25 - 0s - loss: 1.2337 - accuracy: 0.5898 - val_loss: 2.0434 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 94ms/epoch - 4ms/step\n",
            "Epoch 386/1800\n",
            "25/25 - 0s - loss: 1.2362 - accuracy: 0.5911 - val_loss: 2.0428 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 387/1800\n",
            "25/25 - 0s - loss: 1.2188 - accuracy: 0.6051 - val_loss: 2.0424 - val_accuracy: 0.5357 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 388/1800\n",
            "25/25 - 0s - loss: 1.2062 - accuracy: 0.6127 - val_loss: 2.0424 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 96ms/epoch - 4ms/step\n",
            "Epoch 389/1800\n",
            "25/25 - 0s - loss: 1.2195 - accuracy: 0.5860 - val_loss: 2.0415 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 390/1800\n",
            "25/25 - 0s - loss: 1.2350 - accuracy: 0.6025 - val_loss: 2.0425 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 391/1800\n",
            "25/25 - 0s - loss: 1.2067 - accuracy: 0.6051 - val_loss: 2.0429 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 392/1800\n",
            "25/25 - 0s - loss: 1.2390 - accuracy: 0.6013 - val_loss: 2.0416 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 393/1800\n",
            "25/25 - 0s - loss: 1.2193 - accuracy: 0.5898 - val_loss: 2.0400 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 88ms/epoch - 4ms/step\n",
            "Epoch 394/1800\n",
            "25/25 - 0s - loss: 1.2003 - accuracy: 0.5962 - val_loss: 2.0399 - val_accuracy: 0.5408 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 395/1800\n",
            "25/25 - 0s - loss: 1.2584 - accuracy: 0.5796 - val_loss: 2.0408 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 92ms/epoch - 4ms/step\n",
            "Epoch 396/1800\n",
            "25/25 - 0s - loss: 1.1806 - accuracy: 0.6057 - val_loss: 2.0408 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 397/1800\n",
            "25/25 - 0s - loss: 1.2084 - accuracy: 0.5994 - val_loss: 2.0418 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 398/1800\n",
            "25/25 - 0s - loss: 1.2398 - accuracy: 0.5949 - val_loss: 2.0413 - val_accuracy: 0.5510 - lr: 1.0000e-04 - 91ms/epoch - 4ms/step\n",
            "Epoch 399/1800\n",
            "25/25 - 0s - loss: 1.2248 - accuracy: 0.5904 - val_loss: 2.0415 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 87ms/epoch - 3ms/step\n",
            "Epoch 400/1800\n",
            "25/25 - 0s - loss: 1.1808 - accuracy: 0.6025 - val_loss: 2.0410 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 89ms/epoch - 4ms/step\n",
            "Epoch 401/1800\n",
            "25/25 - 0s - loss: 1.1847 - accuracy: 0.5936 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-04 - 90ms/epoch - 4ms/step\n",
            "Epoch 402/1800\n",
            "25/25 - 0s - loss: 1.1740 - accuracy: 0.6083 - val_loss: 2.0414 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 88ms/epoch - 4ms/step\n",
            "Epoch 403/1800\n",
            "25/25 - 0s - loss: 1.1938 - accuracy: 0.6000 - val_loss: 2.0415 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 92ms/epoch - 4ms/step\n",
            "Epoch 404/1800\n",
            "25/25 - 0s - loss: 1.2138 - accuracy: 0.5860 - val_loss: 2.0415 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 91ms/epoch - 4ms/step\n",
            "Epoch 405/1800\n",
            "25/25 - 0s - loss: 1.1863 - accuracy: 0.5930 - val_loss: 2.0414 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 93ms/epoch - 4ms/step\n",
            "Epoch 406/1800\n",
            "25/25 - 0s - loss: 1.2320 - accuracy: 0.5936 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 95ms/epoch - 4ms/step\n",
            "Epoch 407/1800\n",
            "25/25 - 0s - loss: 1.1789 - accuracy: 0.6083 - val_loss: 2.0412 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 92ms/epoch - 4ms/step\n",
            "Epoch 408/1800\n",
            "25/25 - 0s - loss: 1.2240 - accuracy: 0.5892 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-05 - 91ms/epoch - 4ms/step\n",
            "Epoch 409/1800\n",
            "25/25 - 0s - loss: 1.2325 - accuracy: 0.5796 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 90ms/epoch - 4ms/step\n",
            "Epoch 410/1800\n",
            "25/25 - 0s - loss: 1.2270 - accuracy: 0.5898 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 94ms/epoch - 4ms/step\n",
            "Epoch 411/1800\n",
            "25/25 - 0s - loss: 1.2043 - accuracy: 0.5828 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 91ms/epoch - 4ms/step\n",
            "Epoch 412/1800\n",
            "25/25 - 0s - loss: 1.1498 - accuracy: 0.6217 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 93ms/epoch - 4ms/step\n",
            "Epoch 413/1800\n",
            "25/25 - 0s - loss: 1.2126 - accuracy: 0.5987 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 92ms/epoch - 4ms/step\n",
            "Epoch 414/1800\n",
            "25/25 - 0s - loss: 1.1952 - accuracy: 0.6159 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 92ms/epoch - 4ms/step\n",
            "Epoch 415/1800\n",
            "25/25 - 0s - loss: 1.1935 - accuracy: 0.6006 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-06 - 92ms/epoch - 4ms/step\n",
            "Epoch 416/1800\n",
            "25/25 - 0s - loss: 1.2402 - accuracy: 0.5809 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-07 - 95ms/epoch - 4ms/step\n",
            "Epoch 417/1800\n",
            "25/25 - 0s - loss: 1.1832 - accuracy: 0.5866 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-07 - 90ms/epoch - 4ms/step\n",
            "Epoch 418/1800\n",
            "25/25 - 0s - loss: 1.2005 - accuracy: 0.6070 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-07 - 89ms/epoch - 4ms/step\n",
            "Epoch 419/1800\n",
            "25/25 - 0s - loss: 1.2038 - accuracy: 0.5968 - val_loss: 2.0413 - val_accuracy: 0.5459 - lr: 1.0000e-07 - 86ms/epoch - 3ms/step\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=25, verbose=0, mode='min')  \n",
        "reduce_lr_loss = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
        "                  factor=0.1, patience=7, verbose=0, min_delta=1e-119, mode='min')\n",
        "history = model1.fit(train_x, y_train, validation_data=(valid_x, y_valid), class_weight=class_weights_dict45,\n",
        "            shuffle=True, verbose=2, epochs=1800, batch_size=64,\n",
        "            callbacks=[earlyStopping, checkpoint_mlp, reduce_lr_loss])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model\n",
        "from keras.models import load_model\n",
        "best_model = load_model(filepath_mlp)"
      ],
      "metadata": {
        "id": "iGHXy6V2gONJ"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DsUtgBRqOj8f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7bfac69-f4d3-4dbe-c8fc-c98469852bf3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.55"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "valid_accuracy = round(best_model.evaluate(valid_x, y_valid, verbose=0, batch_size=64)[1], 2)\n",
        "valid_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "ScVSLvv4fDv-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "974c7bdd-3871-4406-b587-714b6b499cb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.54      0.78      0.64         9\n",
            "           2       0.00      0.00      0.00         2\n",
            "           3       0.44      0.57      0.50         7\n",
            "           4       0.75      0.60      0.67         5\n",
            "           5       1.00      0.50      0.67         2\n",
            "           6       0.50      0.50      0.50         2\n",
            "           7       1.00      0.50      0.67         2\n",
            "           8       0.50      1.00      0.67         2\n",
            "           9       0.67      0.67      0.67         3\n",
            "          10       0.67      0.67      0.67         9\n",
            "          11       0.67      1.00      0.80         2\n",
            "          12       0.80      0.80      0.80        10\n",
            "          13       0.00      0.00      0.00         2\n",
            "          14       1.00      0.50      0.67         2\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       1.00      0.50      0.67         2\n",
            "          17       0.50      0.50      0.50         2\n",
            "          18       0.75      1.00      0.86         3\n",
            "          19       0.67      1.00      0.80         2\n",
            "          20       0.12      0.29      0.17         7\n",
            "          21       1.00      0.50      0.67         4\n",
            "          22       0.78      0.88      0.82         8\n",
            "          23       0.00      0.00      0.00         2\n",
            "          24       0.67      0.57      0.62         7\n",
            "          25       1.00      0.50      0.67         2\n",
            "          26       0.75      0.75      0.75         4\n",
            "          27       0.71      0.71      0.71         7\n",
            "          28       0.67      0.50      0.57         4\n",
            "          29       0.00      0.00      0.00         2\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       1.00      0.50      0.67         2\n",
            "          32       0.50      0.67      0.57         3\n",
            "          33       0.00      0.00      0.00         4\n",
            "          34       0.20      0.50      0.29         2\n",
            "          35       0.67      1.00      0.80         2\n",
            "          36       0.67      0.40      0.50         5\n",
            "          37       0.50      0.50      0.50         4\n",
            "          38       0.40      0.33      0.36         6\n",
            "          39       0.00      0.00      0.00         4\n",
            "          40       0.21      0.57      0.31         7\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.75      0.60      0.67         5\n",
            "          43       1.00      0.80      0.89        10\n",
            "          44       1.00      0.67      0.80         3\n",
            "          45       1.00      1.00      1.00         2\n",
            "          46       0.00      0.00      0.00         2\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       0.50      0.50      0.50         4\n",
            "          49       0.50      0.25      0.33         4\n",
            "\n",
            "    accuracy                           0.55       196\n",
            "   macro avg       0.54      0.50      0.49       196\n",
            "weighted avg       0.58      0.55      0.55       196\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.67      0.80         3\n",
            "           1       0.83      0.62      0.71         8\n",
            "           2       0.67      1.00      0.80         2\n",
            "           3       0.38      0.71      0.50         7\n",
            "           4       0.83      1.00      0.91         5\n",
            "           5       1.00      1.00      1.00         2\n",
            "           6       1.00      1.00      1.00         2\n",
            "           7       0.00      0.00      0.00         2\n",
            "           8       0.50      0.50      0.50         2\n",
            "           9       1.00      0.50      0.67         2\n",
            "          10       0.64      0.70      0.67        10\n",
            "          11       1.00      0.33      0.50         3\n",
            "          12       0.57      0.40      0.47        10\n",
            "          13       0.20      0.33      0.25         3\n",
            "          14       0.67      1.00      0.80         2\n",
            "          15       0.00      0.00      0.00         2\n",
            "          16       0.50      0.50      0.50         2\n",
            "          17       0.67      0.67      0.67         3\n",
            "          18       1.00      0.67      0.80         3\n",
            "          19       1.00      0.67      0.80         3\n",
            "          20       0.45      0.62      0.53         8\n",
            "          21       0.50      0.75      0.60         4\n",
            "          22       0.70      0.88      0.78         8\n",
            "          23       0.00      0.00      0.00         2\n",
            "          24       0.50      0.86      0.63         7\n",
            "          25       0.00      0.00      0.00         2\n",
            "          26       1.00      1.00      1.00         4\n",
            "          27       0.67      0.67      0.67         6\n",
            "          28       1.00      0.75      0.86         4\n",
            "          29       0.50      0.33      0.40         3\n",
            "          30       0.00      0.00      0.00         2\n",
            "          31       0.50      1.00      0.67         2\n",
            "          32       0.50      0.50      0.50         2\n",
            "          33       1.00      0.25      0.40         4\n",
            "          34       0.00      0.00      0.00         2\n",
            "          35       1.00      1.00      1.00         2\n",
            "          36       0.67      0.50      0.57         4\n",
            "          37       0.50      0.33      0.40         3\n",
            "          38       0.43      0.50      0.46         6\n",
            "          39       0.25      0.25      0.25         4\n",
            "          40       0.12      0.17      0.14         6\n",
            "          41       1.00      0.75      0.86         4\n",
            "          42       0.67      0.80      0.73         5\n",
            "          43       1.00      1.00      1.00        10\n",
            "          44       0.50      0.33      0.40         3\n",
            "          45       0.00      0.00      0.00         2\n",
            "          46       1.00      1.00      1.00         2\n",
            "          47       0.00      0.00      0.00         2\n",
            "          48       0.60      0.75      0.67         4\n",
            "          49       1.00      0.75      0.86         4\n",
            "\n",
            "    accuracy                           0.61       197\n",
            "   macro avg       0.59      0.56      0.55       197\n",
            "weighted avg       0.62      0.61      0.60       197\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model \n",
        "from sklearn.metrics import classification_report\n",
        "assert list(y_test)[0:5] ==  [17, 8, 7, 22, 4]\n",
        "print(classification_report(y_valid, np.array(best_model.predict(valid_x).argmax(-1)),))\n",
        "print(classification_report(y_test, np.array(best_model.predict(test_x).argmax(-1)),))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "QnTRonUbnyqb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 573
        },
        "outputId": "e521081c-a098-41f1-e35f-8ce7411448cc"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "# Training curves\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'valid'], loc = 'upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# References\n",
        "# https://future-chem.com/rdkit-google-colab/#toc5\n",
        "# https://www.rdkit.org/docs/index.html"
      ],
      "metadata": {
        "id": "dmteC1TiiXFE"
      },
      "execution_count": 35,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}